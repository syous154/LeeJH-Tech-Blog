---
{"dg-publish":true,"permalink":"/3-paper-review/yolo-v10/","tags":["Paper"],"created":"2025-02-26T15:44:19.181+09:00","updated":"2025-01-08T20:22:44.106+09:00"}
---

<details> 
<summary>Yolo v10 번역</summary> <div markdown="1"> 


<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">



![그림 1: 지연 시간-정확도(왼쪽) 및 크기-정확도(오른쪽) 트레이드오프 측면에서 다른 모델들과의 비교. 우리는 공식적으로 사전 훈련된 모델을 사용하여 엔드 투 엔드 지연 시간을 측정했습니다.](/img/user/images/Yolov10 review images/Untitled.png)

그림 1: 지연 시간-정확도(왼쪽) 및 크기-정확도(오른쪽) 트레이드오프 측면에서 다른 모델들과의 비교. 우리는 공식적으로 사전 훈련된 모델을 사용하여 엔드 투 엔드 지연 시간을 측정했습니다.

- Yolo 버전 요약
    
    ### YOLOv1 (2016)
    
    - **발표**: Joseph Redmon et al.
    - **핵심 내용**:
        - **속도**: 기존의 영역 제안(region proposal) 기반 탐지 방법들과 달리, 전체 이미지를 단일 패스로 처리하여 객체 탐지를 수행, 매우 빠른 속도를 자랑.
        - **단일 네트워크**: 입력 이미지를 그리드로 분할하고, 각 그리드 셀에서 바운딩 박스와 클래스 확률을 예측.
        - **단점**: 작은 객체에 대한 정확도 낮음, 위치 예측의 정밀도 부족.
    
    ### YOLOv2 (2016, YOLO9000)
    
    - **발표**: Joseph Redmon and Ali Farhadi.
    - **핵심 내용**:
        - **Anchor Boxes 도입**: Faster R-CNN의 앵커 박스 개념을 도입하여 더 나은 위치 예측.
        - **성능 향상**: 더 높은 해상도의 이미지를 처리하며, Batch Normalization과 같은 기법을 통해 성능 향상.
        - **YOLO9000**: 동시에 COCO 및 Open Images와 같은 대규모 데이터셋에서 학습하여, 9000개 이상의 클래스에 대해 실시간 탐지 가능.
    
    ### YOLOv3 (2018)
    
    - **발표**: Joseph Redmon and Ali Farhadi.
    - **핵심 내용**:
        - **다중 스케일 예측**: 3개의 서로 다른 크기의 스케일에서 예측을 수행하여, 작은 객체 탐지 성능 개선.
        - **Darknet-53 백본**: 성능과 효율성을 개선한 53개의 계층을 가진 새로운 백본 아키텍처 사용.
        - **정확도 향상**: 객체 탐지의 정확도가 크게 향상되었지만, 여전히 일부 작은 객체에 대한 문제는 남아 있음.
    
    ### YOLOv4 (2020)
    
    - **발표**: Alexey Bochkovskiy, Chien-Yao Wang, and Hong-Yuan Mark Liao.
    - **핵심 내용**:
        - **성능 최적화**: 다양한 트릭(예: Mosaic Data Augmentation, CmBN, DropBlock 등)을 적용하여, 속도와 정확도 모두 크게 향상.
        - **CSPNet**: 모델의 효율성을 높이기 위해 Cross Stage Partial Network(CSPNet) 도입.
        - **전문가 지식 결합**: 기존의 여러 기법들을 결합하여, 모델의 성능을 극대화.
    
    ### YOLOv5 (2020)
    
    - **발표**: Glenn Jocher (Ultralytics).
    - **핵심 내용**:
        - **PyTorch 구현**: 오픈소스 PyTorch 구현으로, 사용자 친화적이고 쉽게 확장 가능.
        - **지속적인 업데이트**: 다양한 버전(S, M, L, X)과 여러 향상된 기능을 통해 성능 개선.
        - **효율성**: 모델 경량화 및 성능 최적화를 통해 실시간 응용에 적합한 특성 유지.
    
    ### YOLOv6 (2022)
    
    - **발표**: Meituan.
    - **핵심 내용**:
        - **산업적 응용**: 실시간 애플리케이션을 겨냥한 고효율 객체 탐지 모델로 설계.
        - **성능**: YOLOv5에 비해 더 나은 성능과 효율성 제공.
        - **앵커 기반 모델**: 기존 YOLO와 달리 앵커 기반 설계를 유지.
    
    ### YOLOv7 (2022)
    
    - **발표**: Wong Kin-Yiu et al.
    - **핵심 내용**:
        - **모델 효율성**: YOLOv7은 효율적인 학습과 추론을 위해 다양한 최적화 기법을 도입.
        - **다중 모델 크기**: 다양한 크기의 모델(N, S, M, L, X)을 통해 다양한 응용에 맞는 성능 제공.
        - **E-ELAN**: Evolved ELAN 구조를 도입하여 성능 향상.
    
    ### YOLOv8 (2023)
    
    - **발표**: Ultralytics.
    - **핵심 내용**:
        - **모델 성능**: YOLOv5의 후속작으로, 성능과 정확도가 크게 개선됨.
        - **가벼운 구조**: 더욱 가벼운 모델 구조를 통해 빠른 추론과 높은 정확도를 유지.
        - **통합된 학습 및 추론**: PyTorch 기반으로 통합된 학습 및 추론 기능 제공.
    
    ### YOLOv9 (2023)
    
    - **발표**: 발표되지 않음 (미래의 가정).
    - **핵심 내용**: 추측에 기반한 내용으로, 더욱 최적화된 모델 아키텍처와 성능 개선 가능성.
    
    ### YOLOv10 (2024)
    
    - **발표**: 최신 연구 (추측)
    - **핵심 내용**:
        - **NMS-free**: NMS 없이 객체 탐지를 수행할 수 있도록 설계되어, 속도와 효율성 모두 크게 개선.
        - **효율성-정확성 트레이드오프**: 모델 크기와 성능 사이에서 최적의 균형을 맞추기 위한 다양한 전략 도입.
        - **다양한 크기 모델**: N/S/M/B/L/X의 다양한 모델 크기로, 다양한 실시간 응용에 적합.

# 1. 초록 (Abstract)

지난 몇 년간 YOLO는 계산 비용과 탐지 성능 간의 균형을 효과적으로 맞추며 실시간 객체 탐지 분야에서 지배적인 패러다임으로 자리 잡았습니다. 연구자들은 YOLO의 아키텍처 디자인, 최적화 목표, 데이터 증강 전략 등을 탐구하여 상당한 진전을 이루었습니다. **그러나 비최대 억제(NMS)에 의존하는 후처리 과정은 YOLO의 엔드 투 엔드 배포를 저해하고 추론 지연에 부정적인 영향을 미칩니다**. 또한, **YOLO의 다양한 구성 요소 설계는 종합적이고 철저한 검토가 부족하여 계산상의 중복이 두드러지며 모델의 능력을 제한합니다. 이는 비효율성을 초래하고, 성능 향상의 잠재력을 제한합니다.**

**본 연구에서는 YOLO의 성능-효율성 경계를 후처리와 모델 아키텍처 양측에서 더욱 향상시키는 것을 목표로 합니다.** 이를 위해 먼저 YOLO의 **NMS 없는 훈련을 위해 일관된 이중 할당 전략을 제시**하여, 경쟁력 있는 성능과 낮은 추론 지연 시간을 동시에 제공합니다. 또한, YOLO의 전반적인 효율성-정확성 중심의 모델 설계 전략을 소개하여, 효율성과 정확성 관점에서 YOLO의 다양한 구성 요소를 종합적으로 최적화했습니다. 이로써 계산 오버헤드를 크게 줄이고 모델의 능력을 강화했습니다. 이러한 노력을 통해 실시간 엔드 투 엔드 객체 탐지를 위한 새로운 YOLO 시리즈인 YOLOv10을 개발했습니다. 광범위한 실험을 통해 YOLOv10은 다양한 모델 스케일에서 최첨단 성능과 효율성을 달성함을 확인했습니다. 예를 들어, **YOLOv10-S는 유사한 COCO AP 성능을 유지하면서 RT-DETR-R18보다 1.8배 더 빠르고, 파라미터와 FLOPs 수가 2.8배 적습니다. YOLOv9-C와 비교했을 때, YOLOv10-B는 성능이 동일한 상태에서 지연 시간이 46% 감소하고, 파라미터 수는 25% 감소했습니다.**

Code: [https://github.com/THU-MIG/yolov10](https://github.com/THU-MIG/yolov10).

# 2. 소개 (Introduction)

실시간 객체 탐지는 컴퓨터 비전 분야에서 중요한 연구 주제였으며, 이는 낮은 지연 시간으로 이미지 내의 객체의 범주와 위치를 정확하게 예측하는 것을 목표로 합니다. 자율주행 [3], 로봇 내비게이션 [11], 객체 추적 [66] 등 다양한 실제 응용 분야에서 널리 사용되고 있습니다. 최근 몇 년 동안 연구자들은 실시간 탐지를 달성하기 위해 CNN 기반 객체 탐지기를 설계하는 데 집중해 왔습니다 [18, 22, 43, 44, 45, 51, 12]. 그 중에서도 YOLO는 성능과 효율성 사이의 뛰어난 균형 덕분에 점점 더 인기를 얻고 있습니다 [2, 19, 27, 19, 20, 59, 54, 64, 7, 65, 16, 27]. **YOLO의 탐지 파이프라인은 모델 전방 처리와 NMS 후처리의 두 부분으로 구성됩니다. 그러나 두 부분 모두 여전히 결함이 있어, 최적의 정확도-지연 경계에 도달하는 데 어려움이 있습니다.**

구체적으로, YOLO는 훈련 중에 보통 다수의 양성 샘플에 하나의 실제 객체를 할당하는 방식(one-to-many label assignment)을 사용합니다. 이 방법은 우수한 성능을 제공하지만, 추론 중에 최적의 양성 예측을 선택하기 위해 NMS가 필요합니다. 이는 추론 속도를 저하시킬 뿐만 아니라 YOLO의 최적의 엔드 투 엔드 배포를 방해하는 NMS 하이퍼파라미터에 민감한 성능을 유발합니다. 이를 해결하기 위한 한 가지 방법은 최근 도입된 엔드 투 엔드 DETR 아키텍처 [4, 74, 67, 28, 34, 40, 61]를 사용하는 것입니다. 예를 들어, RT-DETR [71]는 효율적인 하이브리드 인코더와 불확실성을 최소화한 쿼리 선택을 제시하여 DETR을 실시간 응용 분야로 확장했습니다. 그러나 DETR의 복잡한 배포는 정확성과 속도 사이의 최적 균형을 달성하는 능력을 방해합니다. 다른 방법으로는, CNN 기반 탐지기를 위한 엔드 투 엔드 탐지를 탐구하는 것으로, 이는 보통 중복된 예측을 억제하기 위해 일대일 할당 전략(one-to-one assignment strategies)을 사용합니다 [5, 49, 60, 73, 16]. 그러나 이 방법은 보통 추가적인 추론 오버헤드를 도입하거나 최적의 성능을 달성하지 못합니다.

또한, 모델 아키텍처 설계는 여전히 YOLO에 대한 근본적인 도전 과제이며, 이는 정확도와 속도에 중요한 영향을 미칩니다 [45, 16, 65, 7]. 보다 효율적이고 효과적인 모델 아키텍처를 달성하기 위해, 연구자들은 다양한 설계 전략을 탐구해 왔습니다. 다크넷(DarkNet) [43, 44, 45], CSPNet [2], EfficientRep [27], ELAN [56, 58] 등과 같은 주요 컴퓨팅 유닛이 백본에서 기능 추출 능력을 향상시키기 위해 제안되었습니다. 네크(Neck)에서는, PAN [35], BiC [27], GD [54], RepGFPN [65] 등이 다중 스케일 기능 융합을 향상시키기 위해 탐구되었습니다. 또한, 모델 스케일링 전략 [56, 55] 및 재구성 기법 [10, 27]도 조사되었습니다. 이러한 노력들은 주목할 만한 발전을 이루었지만, 효율성과 정확성 측면에서 YOLO의 다양한 구성 요소에 대한 종합적인 검토는 여전히 부족합니다. 그 결과, YOLO 내에는 상당한 계산 중복이 존재하며, 이는 비효율적인 파라미터 활용과 최적의 효율성을 제한합니다. 이로 인해 모델의 능력도 제한되어 정확도 향상 가능성이 남아 있습니다​.

# 3. 관련 연구 (Related Work)

## **3.1 실시간 객체 탐지기**

실시간 객체 탐지는 낮은 지연 시간 내에 객체를 분류하고 위치를 파악하는 것을 목표로 하며, 이는 실제 응용 프로그램에서 매우 중요합니다. 지난 몇 년간, 효율적인 탐지기를 개발하기 위한 상당한 노력이 이루어졌습니다 [18, 51, 43, 32, 72, 69, 30, 29, 39]. 특히 YOLO 시리즈 [43, 44, 45, 2, 19, 27, 56, 20, 59]는 주류 탐지기로서 두각을 나타내고 있습니다. 

YOLOv1, YOLOv2, 그리고 YOLOv3는 백본, 넥, 헤드라는 세 부분으로 구성된 전형적인 탐지 아키텍처를 식별합니다 [43, 44, 45]. 

YOLOv4 [2]와 YOLOv5 [19]는 다크넷(DarkNet) [42]을 대체하기 위해 CSPNet [57] 설계를 도입했으며, 데이터 증강 전략, 향상된 PAN, 다양한 모델 스케일 등이 추가되었습니다. 

YOLOv6 [27]는 넥과 백본에 각각 BiC와 SimCSPSPPF를 도입했으며, 앵커 기반 학습 및 자기 증류 전략을 도입했습니다. 

YOLOv7 [56]은 풍부한 그래디언트 흐름 경로를 제공하기 위해 E-ELAN을 도입하고 여러 학습 가능한 무료 기법을 탐구했습니다.

YOLOv8 [20]은 효과적인 특징 추출과 융합을 위한 C2f 빌딩 블록을 도입했습니다. Gold-YOLO [54]는 다중 스케일 특징 융합 기능을 강화하기 위해 고급 GD 메커니즘을 제공했습니다. 

YOLOv9 [59]는 아키텍처 개선을 위해 GELAN을 제안하고 학습 과정을 증강하기 위해 PGI를 도입했습니다.

## **3.2 엔드 투 엔드 객체 탐지기**

엔드 투 엔드 객체 탐지는 전통적인 파이프라인에서 벗어나, 간소화된 아키텍처를 제공하며 [48], 탐지 분야에서 패러다임의 전환을 일으켰습니다. 

DETR [4]은 트랜스포머 아키텍처를 도입하고 헝가리안 손실(Hungarian loss)을 채택하여 일대일 매칭 예측을 실현하여, 수작업 구성 요소와 후처리를 제거했습니다. 이후, 성능과 효율성을 향상시키기 위해 다양한 DETR 변형 모델들이 제안되었습니다 [40, 61, 50, 28, 34]. 

Deformable-DETR [74]는 수렴 속도를 가속화하기 위해 멀티 스케일 변형 가능한 주의 모듈을 활용합니다. DINO [67]는 DETR에 대조적 디노이징(contrastive denoising), 쿼리 선택 혼합(mix query selection), 두 번 보기(look forward twice) 스킴을 통합했습니다. 

RT-DETR [71]은 효율적인 하이브리드 인코더를 설계하고 불확실성을 최소화한 쿼리 선택을 제안하여 정확성과 지연 시간을 모두 향상시켰습니다. 또 다른 엔드 투 엔드 객체 탐지를 실현하는 방법은 CNN 기반 탐지기입니다. 

학습 가능한 NMS [23]와 관계 네트워크 [25]는 탐지기를 위한 중복된 예측을 제거하기 위해 또 다른 네트워크를 제공합니다. 

OneNet [49]과 DeFCN [60]은 완전히 컨볼루션 네트워크를 통해 엔드 투 엔드 객체 탐지를 가능하게 하기 위해 일대일 매칭 전략을 제안했습니다. FCOSpss [73]은 예측을 위한 최적의 샘플을 선택하기 위해 긍정적 샘플 선택기를 도입했습니다.

# 4. 방법론 (Methodology)

## 4.1 NMS-Free 훈련을 위한 일관된 이중 할당 전략

훈련 중, YOLO는 [20, 59, 27, 64] TAL [14]을 활용하여 각 인스턴스에 대해 다수의 긍정 샘플을 할당합니다. 다중 할당 방식을 채택하면 풍부한 지도 신호를 제공하여 최적화를 촉진하고 우수한 성능을 달성할 수 있습니다. 

그러나 **이는 YOLO가 비최대 억제(NMS) 후처리에 의존하게 만들어 배포 시 비효율적인 추론 성능을 초래합니다**. 이전 작업들 [49, 60, 73, 5]에서는 중복된 예측을 억제하기 위해 일대일 매칭을 탐구했지만, 이들은 보통 추가적인 추론 오버헤드를 도입하거나 최적의 성능을 내지 못합니다. 

**본 연구에서는 YOLO를 위해 이중 레이블 할당과 일관된 매칭 메트릭을 갖춘 NMS 없는 훈련 전략을 제안하여 높은 효율성과 경쟁력 있는 성능을 동시에 달성합니다.**

### **이중 레이블 할당(Dual label assignments)**

![**그림 2** : (a) NMS가 필요 없는 훈련을 위한 일관된 이중 할당. (b) 기본적으로 $\alpha_{o2m}=0.5$ 및 $\beta_{o2m}=6$ 을 사용하는 YOLOv8-S에서 일대다 결과의 상위 1/5/10에서 일대일 할당 빈도 [20](/img/user/images/Untitled 1.png)

**그림 2** : (a) NMS가 필요 없는 훈련을 위한 일관된 이중 할당. (b) 기본적으로 $\alpha_{o2m}=0.5$ 및 $\beta_{o2m}=6$ 을 사용하는 YOLOv8-S에서 일대다 결과의 상위 1/5/10에서 일대일 할당 빈도 [20]. 일관성을 위해, $\alpha_{o2o}=0.5$ $\alpha_{o2o}=0.5$\beta_{o2o}=6$ 일관성 없는 경우, $\alpha_{o2o}=0.5$; $\beta_{o2o}=2$

**다중 할당 방식과 달리 일대일 매칭은 각 실제 객체에 하나의 예측만을 할당하여 NMS 후처리를 피할 수 있습니다. 그러나 이는 약한 지도 학습을 유발하여 최적의 정확도와 수렴 속도를 방해합니다** [75]. 다행히도 **이러한 결점은 다중 할당 방식에 의해 보완될 수 있습니다** [5]. **이를 달성하기 위해, YOLO에 이중 레이블 할당을 도입하여 두 전략의 장점을 결합합니다.** 구체적으로, 그림 2.(a)와 같이 YOLO에 또 다른 일대일 헤드를 통합합니다. 이 헤드는 동일한 구조를 유지하며, 원래의 다중 할당 분기와 동일한 최적화 목표를 채택하지만, 일대일 매칭을 활용하여 레이블 할당을 얻습니다. 훈련 중에는 두 개의 헤드가 모델과 함께 공동으로 최적화되어 백본과 넥이 다중 할당 방식이 제공하는 풍부한 지도를 누릴 수 있습니다. **추론 중에는 다중 할당 헤드를 버리고 일대일 헤드를 사용하여 예측을 수행합니다. 이를 통해 YOLO는 추가적인 추론 비용 없이 엔드 투 엔드 배포가 가능합니다.** 또한, 일대일 매칭에서는 최상위 선택 방식을 채택하여 헝가리 매칭 [4]과 동일한 성능을 더 적은 훈련 시간으로 달성합니다.

### **일관된 매칭 메트릭(Consistent matching metric)**

> o2o → one to one head, o2m → one to many head
> 

할당 중, 일대일과 다중 할당 방식 모두 예측과 인스턴스 간의 일치 정도를 정량적으로 평가하기 위해 메트릭을 활용합니다. 두 가지 분기에 대한 예측 인식 매칭을 달성하기 위해, 우리는 다음과 같은 통일된 매칭 메트릭을 사용합니다:
$m(\alpha, \beta) = s \cdot p^\alpha \cdot \text{IoU}(\hat{b}, b)^\beta$
여기서 $p$는 분류 점수를 나타내며, $\hat{b}$와 $b$는 각각 예측과 인스턴스의 바운딩 박스를 나타냅니다. $s$는 예측의 앵커 포인트가 인스턴스 내에 있는지 여부를 나타내는 공간적 우선순위를 나타냅니다 [20, 59, 27, 64]. $\alpha$와 $\beta$는 의미 예측 작업과 위치 회귀 작업의 영향을 균형 있게 조절하는 중요한 하이퍼파라미터입니다. 우리는 다중 할당 메트릭과 일대일 메트릭을 각각 $m_{\text{o2m}} = m(\alpha_{\text{o2m}}$, $\beta_{\text{o2m}})$과 $m_{\text{o2o}} = m(\alpha_{\text{o2o}}, \beta_{\text{o2o}})$로 나타냅니다. 이러한 메트릭은 두 헤드에 대한 레이블 할당 및 지도 정보를 제공합니다.

**이중 레이블 할당에서는 일대다 분기가 일대일 분기보다 훨씬 더 풍부한 지도 신호를 제공합니다.** 직관적으로, 일대일 헤드의 지도를 일대다 헤드와 조화롭게 맞출 수 있다면, 일대일 헤드를 일대다 헤드의 최적화 방향으로 최적화할 수 있습니다. **결과적으로, 일대일 헤드는 추론 중 더 나은 샘플 품질을 제공하여 성능을 향상시킬 수 있습니다.** 이를 위해, 우리는 두 헤드 간의 지도 격차를 분석했습니다. 훈련 중 무작위성 때문에, 우리는 동일한 값으로 초기화된 두 헤드를 동일한 예측을 생성하는 것으로 가정하여 초기 분석을 시작했습니다. 두 분기의 회귀 대상은 충돌하지 않으며, 일치하지 않은 예측은 무시되므로 동일한 대상에 대해 일치된 예측을 공유합니다. 지도 격차는 다른 분류 대상에서 비롯됩니다. 주어진 인스턴스의 경우, 예측과의 가장 큰 $IoU$를 $u^*$로 나타내고, 일대다 및 일대일 매칭 점수를 각각 $m^*_{\text{o2m}}$ 과 $m^*_{\text{o2o}}$ 로 나타냅니다. 일대다 분기가 양성 샘플 $Ω$을 생성하고, 일대일 분기가 i번째 예측을 $m_{\text{o2o,i}} = m^*_{\text{o2o}}$ 로 선택한다고 가정하면, 분류 대상은 $t_{\text{o2m,j}} = u^* \cdot \frac{m_{\text{o2m,j}}}{m^*_{\text{o2m}}} \leq u^*$ 이며 $t_{\text{o2o,i}} = u^* \cdot \frac{m_{\text{o2o,i}}}{m^*_{\text{o2o}}} = u^*$ 입니다.

$A = t_{o2o,i} - I(i \in \Omega) t_{o2m,i} + \sum_{k \in \Omega \setminus \{i\}} t_{o2m,k}$

우리는 $t_{o2m,i}$가 증가함에 따라 갭이 감소하는 것을 관찰할 수 있으며, 이는 $i$가 $\Omega$ 내에서 더 높은 순위를 차지함을 의미합니다. 이는 $t_{o2m,i}=u^*$일 때 최소에 도달하며, 즉 $i$가 $\Omega$에서 가장 좋은 긍정 샘플임을 나타냅니다(그림 2.(a) 참조). 이를 달성하기 위해, 우리는 일관된 매칭 메트릭$\alpha_{o2o}=r \cdot \alpha_{o2m}$ 및 $\beta_{o2o}=r \cdot \beta_{o2m}$을 제시합니다. 이는 $m_{o2o}=m_{o2m}^r$을 의미합니다. 따라서, 일대다 헤드에서 최고의 긍정 샘플은 일대일 헤드에서도 최고의 샘플이 됩니다. 결과적으로, 두 헤드는 일관되고 조화롭게 최적화될 수 있습니다. 단순함을 위해, 기본적으로 $r=1$, 즉 $\alpha_{o2o}=\alpha_{o2m}$ 및 $\beta_{o2o}=\beta_{o2m}$으로 설정합니다. 개선된 지도 정렬을 검증하기 위해, 훈련 후 일대다 결과의 상위 1 / 5 / 10 내에서 일대일 매칭 쌍의 수를 셉니다. 그림 2.(b)에서 볼 수 있듯이, 일관된 매칭 메트릭 하에서 정렬이 개선되었습니다. 수학적 증명에 대한 더 포괄적인 이해를 위해서는 부록을 참조하십시오.

## 4.2 전반적인 효율성-정확성 중심의 모델 설계

![](/img/user/images/Untitled 2.png)

그림 3. (a) YOLOv8에서 스테이지와 모델 전반에 걸친 고유 랭크. 백본과 넥의 스테이지는 모델의 순방향 처리 순서에 따라 번호가 매겨져 있습니다. 수치 랭크  $r$은 y축에서 $r/C_o$로 정규화되며, 임계값은 기본적으로 $λ_{max}/2$로 설정됩니다. 여기서 $C_o$는 출력 채널 수를 나타내고, $λ_{max}$는 가장 큰 특이값을 의미합니다. 깊은 스테이지와 큰 모델이 더 낮은 고유 랭크 값을 나타냅니다. 
(b) 컴팩트 인버티드 블록(CIB). 
(c) 부분 자기 주의 모듈(PSA).

후처리와 더불어, YOLO 모델의 아키텍처는 효율성-정확성 트레이드오프에 큰 도전 과제를 제기합니다 [45, 7, 27]. 이전 연구들이 다양한 설계 전략을 탐구했지만, YOLO의 다양한 구성 요소에 대한 종합적인 검토는 여전히 부족합니다. 그 결과, 모델 아키텍처는 무시할 수 없는 계산적 중복성과 제한된 능력을 나타내며, 이는 높은 효율성과 성능을 달성할 잠재력을 방해합니다. 여기서는 효율성과 정확성 관점에서 YOLO 모델을 전반적으로 설계하는 것을 목표로 합니다.

### **효율성 중심 모델 설계**

YOLO의 구성 요소는 스템(stem), 다운샘플링 레이어(downsampling layers), 기본 빌딩 블록이 포함된 스테이지(stages with basic building blocks), 그리고 헤드(head)로 구성됩니다. 스템은 적은 계산 비용을 발생시키므로, 효율성 중심의 모델 설계는 나머지 세 부분에서 수행됩니다.

**(1) 경량 분류 헤드(Lightweight classification head):**

YOLO 모델에서는 보통 분류 헤드와 회귀 헤드가 동일한 구조를 공유합니다. 그러나 두 헤드는 계산 오버헤드에서 현저한 차이를 보입니다. 예를 들어, YOLOv8-S에서 분류 헤드의 FLOPs와 파라미터 수(5.95G/1.51M)는 회귀 헤드의 FLOPs와 파라미터 수(2.34G/0.64M)보다 각각 2.5배와 2.4배 더 큽니다. 그러나 분류 오류와 회귀 오류가 YOLO 성능에 미치는 영향을 분석한 결과, 회귀 헤드가 YOLO 성능에 더 중요한 역할을 한다는 것을 알 수 있습니다. 따라서 분류 헤드의 오버헤드를 줄여도 성능 저하에 대한 우려 없이 모델을 경량화할 수 있습니다. 이에 따라, 우리는 커널 크기가 3×3인 두 개의 깊이 분리형 컨볼루션(depthwise separable convolutions)과 1×1 컨볼루션으로 구성된 경량 아키텍처를 분류 헤드에 채택했습니다.

**(2) 공간-채널 분리 다운샘플링(Spatial-channel decoupled downsampling):**

YOLO는 보통 3×3 표준 컨볼루션을 스트라이드 2로 활용하여 공간 다운샘플링(해상도를 $H × W$에서 $\frac{H}2 × \frac{W}2$로 줄임)과 채널 변환(채널 수를 $C$에서 $2C$로 증가)을 동시에 수행합니다. 이는 $O(\frac{9}2 HWC^2)$의 계산 비용과 $O(18C^2)$의 파라미터 수를 발생시킵니다. 대신, 우리는 공간 감소와 채널 증가 작업을 분리하여 보다 **효율적인 다운샘플링을 제안합니다.** 구체적으로, **먼저 포인트와이즈 컨볼루션(pointwise convolution)을 사용하여 채널 차원을 조절하고, 이후 깊이별 컨볼루션(depthwise convolution)을 이용해 공간 다운샘플링을 수행합니다.** 이를 통해 계산 비용을 $O(2HWC^2 + \frac{9}2HWC)$로, 파라미터 수를 $O(2C^2 + 18C)$로 줄일 수 있으며, 다운샘플링 중 정보 손실을 최소화하여 성능과 지연 시간을 줄이는 데 기여합니다.

**(3) 랭크 기반 블록 설계(Rank-guided block design):**

YOLO 모델들은 보통 모든 스테이지에 동일한 기본 빌딩 블록을 사용합니다 [27, 59]. 예를 들어, YOLOv8에서는 병목 블록(bottleneck block)을 사용합니다 [20]. 이러한 균일한 설계가 YOLO에 최적인지 철저히 조사하기 위해, 우리는 각 스테이지의 중복성을 분석하기 위해 고유 랭크(intrinsic rank)를 활용했습니다. 

구체적으로, 우리는 각 스테이지의 마지막 기본 블록에서 마지막 컨볼루션의 수치적 랭크를 계산하여, 임계값보다 큰 특이값의 수를 셉니다. 그림 3.(a)는 YOLOv8의 결과를 나타내며, 깊은 스테이지와 큰 모델이 더 낮은 고유 랭크 값을 보이는 경향이 있음을 보여줍니다. 이러한 관찰은 모든 스테이지에 동일한 블록 설계를 적용하는 것이 최고의 성능-효율성 트레이드오프를 위해 최적이 아님을 시사합니다. 이를 해결하기 위해, 우리는 랭크 기반 블록 설계 방식을 제안하여, 중복성이 많은 스테이지에 대해 복잡성을 줄이기 위한 컴팩트한 아키텍처 설계를 제공합니다. 

먼저, 우리는 공간 혼합을 위한 저렴한 깊이별 컨볼루션과 채널 혼합을 위한 비용 효율적인 포인트와이즈 컨볼루션을 채택한 컴팩트 인버티드 블록(compact inverted block, CIB) 구조를 제안합니다. 이 블록은 ELAN 구조 [58, 20]에 효율적인 기본 빌딩 블록으로 삽입될 수 있습니다. 그런 다음, 우리는 최고의 효율성을 유지하면서 경쟁력 있는 용량을 유지하기 위해, 랭크 기반 블록 할당 전략을 제안합니다. 구체적으로, 주어진 모델의 모든 스테이지를 고유 랭크에 따라 오름차순으로 정렬한 후, 스테이지의 기본 블록을 CIB로 교체했을 때 성능 저하가 없으면 다음 스테이지로 이동하고, 그렇지 않으면 프로세스를 중단합니다. 이를 통해, 스테이지와 모델 규모에 따라 적응적으로 컴팩트한 블록 설계를 구현하여, 성능 저하 없이 더 높은 효율성을 달성할 수 있습니다. 알고리즘의 자세한 내용은 부록에 제공합니다.

### **정확성 중심 모델 설계(Accuracy driven model design)**

효율성 중심 설계 외에도, 정확성 중심 설계를 통해 비용을 최소화하면서 성능을 극대화하기 위해 대형 커널 컨볼루션과 자기 주의(self-attention)를 탐구합니다.

**(1) 대형 커널 컨볼루션(Large-kernel convolution):**

대형 커널 깊이별 컨볼루션을 사용하는 것은 수용 영역을 확장하고 모델의 능력을 향상시키는 효과적인 방법입니다 [9, 38, 37]. 그러나 이를 모든 스테이지에 단순히 적용하면, 작은 객체를 탐지하는 데 사용되는 얕은 특징이 오염되고, 고해상도 스테이지에서 상당한 I/O 오버헤드와 지연을 초래할 수 있습니다 [7]. 따라서, 우리는 깊은 스테이지 내에서 CIB의 두 번째 3×3 깊이별 컨볼루션의 커널 크기를 7×7로 증가시키는 방식을 제안합니다 [37]. 추가로, 구조적 재구성 기법 [10, 9, 53]을 사용하여 최적화 문제를 완화하기 위해, 또 다른 3×3 깊이별 컨볼루션 분기를 추가합니다. 또한, 모델 크기가 커지면, 수용 영역이 자연스럽게 확장되므로 대형 커널 컨볼루션의 이점이 감소합니다. 따라서, 우리는 대형 커널 컨볼루션을 작은 모델 크기에만 적용합니다.

**(2) 부분 자기 주의(Partial self-attention, PSA):**

자기 주의(self-attention) [52]는 뛰어난 글로벌 모델링 능력 덕분에 다양한 비전 작업에서 널리 사용됩니다 [36, 13, 70]. 그러나 이는 높은 계산 복잡성과 메모리 사용량을 나타냅니다. 이를 해결하기 위해, 주의 헤드의 중복성을 완화하기 위해 [63], 우리는 효율적인 부분 자기 주의(PSA) 모듈을 설계합니다. 구체적으로, 우리는 1×1 컨볼루션 이후 채널을 두 부분으로 균등하게 분할한 후, 한 부분만을 MHSA(다중 헤드 자기 주의 모듈)와 FFN(피드포워드 네트워크)로 구성된 NPSA 블록에 입력합니다. 그런 다음, 두 부분을 결합하여 1×1 컨볼루션으로 융합합니다. 또한, [21]을 따라 MHSA에서 쿼리와 키의 차원을 값의 절반으로 할당하고, 빠른 추론을 위해 LayerNorm [1]을 BatchNorm [26]으로 대체합니다. 추가로, PSA는 가장 낮은 해상도의 스테이지 4 이후에만 배치하여 오버헤드를 줄입니다. 이를 통해, 우리는 효율성과 정확성 사이의 균형을 맞춘 적응형 블록 설계를 구현합니다.

# 5. 실험 (Experiments)

## 5.1 구현 세부사항

YOLOv8 [20]을 기본 모델로 선택한 이유는 뛰어난 지연 시간-정확도 균형을 가지고 있으며, 다양한 모델 크기로 제공되기 때문입니다. 우리는 NMS가 필요 없는 훈련을 위해 일관된 이중 할당 전략을 사용하고, 이를 바탕으로 효율성-정확도 중심의 모델 설계를 수행하여 YOLOv10 모델을 만들었습니다. YOLOv10은 YOLOv8과 동일한 N / S / M / L / X 변형을 가지고 있으며, YOLOv10-M의 너비 스케일 팩터를 증가시켜 새로운 변형인 YOLOv10-B를 도출했습니다. COCO [33] 데이터셋에서 동일한 초기부터 학습하는 설정에서 제안된 탐지기를 검증하였습니다. 또한, 모든 모델의 지연 시간은 [71]에 따라 T4 GPU에서 TensorRT FP16으로 테스트했습니다.

## 5.2 최신 기술과의 비교

![표 1: 최신 기술들과의 비교. 지연 시간은 공식적으로 사전 훈련된 모델을 사용하여 측정되었습니다. $Latency^f$는 후처리 없이 모델의 순방향 처리 과정에서의 지연 시간을 나타냅니다. $†$는 NMS를 사용하는 원래의 일대다 훈련을 통해 얻은 YOLOv10의 결과를 의미합니다. 공정한 비교를 위해, 아래의 모든 결과는 지식 증류나 PGI와 같은 추가적인 고급 훈련 기술을 사용하지 않았습니다.](/img/user/images/Yolov10 review images/Untitled 3.png)

표 1: 최신 기술들과의 비교. 지연 시간은 공식적으로 사전 훈련된 모델을 사용하여 측정되었습니다. $Latency^f$는 후처리 없이 모델의 순방향 처리 과정에서의 지연 시간을 나타냅니다. $†$는 NMS를 사용하는 원래의 일대다 훈련을 통해 얻은 YOLOv10의 결과를 의미합니다. 공정한 비교를 위해, 아래의 모든 결과는 지식 증류나 PGI와 같은 추가적인 고급 훈련 기술을 사용하지 않았습니다.

표 1에 나타난 바와 같이, 우리의 YOLOv10은 다양한 모델 크기에서 최첨단 성능과 엔드 투 엔드 지연 시간을 달성했습니다. 먼저, YOLOv10을 기본 모델인 YOLOv8과 비교했습니다. N / S / M / L / X의 다섯 가지 변형에서 우리의 YOLOv10은 1.2% / 1.4% / 0.5% / 0.3% / 0.5% AP 개선을 달성했으며, 28% / 36% / 41% / 44% / 57%의 더 적은 파라미터, 23% / 24% / 25% / 27% / 38%의 더 적은 계산, 그리고 70% / 65% / 50% / 41% / 37%의 더 낮은 지연 시간을 보였습니다. 다른 YOLO 모델들과 비교했을 때도, YOLOv10은 정확도와 계산 비용 간의 뛰어난 균형을 보여주었습니다. 특히 경량화된 모델과 소형 모델에서, YOLOv10-N / S는 YOLOv6-3.0-N / S보다 각각 1.5 AP와 2.0 AP 더 우수했습니다. 중간 모델에서는, YOLOv9-C / YOLO-MS와 비교했을 때 YOLOv10-B / M은 동일하거나 더 나은 성능에서 각각 46% / 62%의 지연 시간 감소를 누렸습니다. 대형 모델에서는, Gold-YOLO-L과 비교했을 때 우리의 YOLOv10-L은 68% 더 적은 파라미터와 32% 더 낮은 지연 시간을 보였으며, 1.4% AP의 상당한 개선을 보여주었습니다. 또한, RT-DETR과 비교했을 때, YOLOv10은 성능과 지연 시간에서 큰 개선을 이루었습니다. 특히, YOLOv10-S / X는 RT-DETR-R18 / R101보다 각각 1.8배, 1.3배 더 빠른 추론 속도를 달성하면서 유사한 성능을 보여주었습니다. 이러한 결과는 YOLOv10이 실시간 엔드 투 엔드 탐지기로서의 우수성을 잘 입증합니다.

우리는 또한 YOLOv10을 다른 YOLO 모델들과 비교했습니다. 이 비교에서는 NMS 없이 원래의 일대다 훈련 접근법을 사용했으며, 모델의 순방향 처리 과정(Latencyf)에서의 성능과 지연 시간을 고려했습니다. 표 1에서 볼 수 있듯이, YOLOv10은 다양한 모델 스케일에서 최첨단 성능과 효율성을 보여주었으며, 우리의 아키텍처 설계의 효과를 입증했습니다.

## 5.3 모델 분석

![Untitled](/img/user/images/Yolo images/Untitled 4.png)

![Untitled](/img/user/images/Yolo images/Untitled 5.png)

### **5.3.1 절충 연구(Ablation study)**

표 2에 기반한 YOLOv10-S 및 YOLOv10-M의 절충 결과를 제시합니다. 우리의 NMS가 필요 없는 훈련은 YOLOv10-S의 엔드 투 엔드 지연 시간을 4.63ms 줄이면서도 44.3% AP의 경쟁력 있는 성능을 유지함을 알 수 있습니다. 또한, 효율성 중심 모델 설계는 11.8M의 파라미터와 20.8 GFLOPs를 줄이며, YOLOv10-M의 지연 시간을 0.65ms 상당히 줄이는 데 기여했습니다. 더불어, 정확도 중심 모델 설계는 YOLOv10-S와 YOLOv10-M에 대해 각각 1.8 AP와 0.7 AP의 현저한 개선을 가져왔으며, 지연 시간 오버헤드는 각각 0.18ms와 0.17ms에 불과했습니다. 이는 우리 설계 전략의 우수성을 잘 보여줍니다.

### **5.3.2 NMS-Free 훈련을 위한 분석:**

- **이중 레이블 할당(Dual label assignments)**
우리는 NMS가 필요 없는 YOLO를 위해 이중 레이블 할당 방식을 제시하며, 이는 훈련 시 일대다(o2m) 분기의 풍부한 지도 신호와 추론 시 일대일(o2o) 분기의 높은 효율성을 동시에 가져올 수 있습니다. 우리는 YOLOv8-S를 기반으로 이 방식의 이점을 검증했습니다(표 2의 #1). 구체적으로, 우리는 o2m 분기만 사용하는 훈련과 o2o 분기만 사용하는 훈련을 각각 소개했습니다. 표 3에서 볼 수 있듯이, 우리의 이중 레이블 할당 방식은 최고의 AP-지연 시간 트레이드오프를 달성했습니다.
- **일관된 매칭 메트릭(Consistent matching metric)**
우리는 일대일 헤드가 일대다 헤드와 더 조화를 이루도록 일관된 매칭 메트릭을 도입했습니다. 우리는 이를 YOLOv8-S(표 2의 #1)를 기반으로 다양한 αo2o와 βo2o에서 검증했습니다. 표 4에서 볼 수 있듯이, 제안된 일관된 매칭 메트릭, 즉 $α_{o2o}=r⋅α_{o2m}$ 및 $β_{o2o}=r⋅β_{o2m}$은 최적의 성능을 달성할 수 있으며, 여기서 $α_{o2m}=0.5$ 및 $β_{o2m}=6.0$은 일대다 헤드에서 사용되었습니다 [20]. 이러한 개선은 지도 간격의 감소(Eq. (2))에 기인하며, 이는 두 분기 간의 지도 정렬을 개선합니다. 또한, 제안된 일관된 매칭 메트릭은 실용적인 시나리오에서 매력적인 하이퍼파라미터 조정의 필요성을 없애줍니다.

### **5.3.4 효율성 중심 모델 설계를 위한 분석**

우리는 YOLOv10-S/M을 기반으로 효율성 중심 설계 요소들을 점진적으로 통합하는 실험을 수행했습니다. 우리의 기준 모델은 효율성-정확성 중심 모델 설계가 없는 YOLOv10-S/M 모델입니다(표 2의 #2/#6). 표 5에서 볼 수 있듯이, 경량화된 분류 헤드, 공간-채널 분리 다운샘플링, 그리고 랭크 기반 블록 설계를 포함한 각 설계 구성 요소는 파라미터 수, FLOPs, 그리고 지연 시간 감소에 기여했습니다. 특히, 이러한 개선은 경쟁력 있는 성능을 유지하면서 달성되었습니다.

- **경량화된 분류 헤드(Lightweight classification head)**
우리는 표 5의 #1과 #2에 있는 YOLOv10-S를 기반으로 예측의 카테고리 및 위치 오류가 성능에 미치는 영향을 분석했습니다. 구체적으로, 우리는 일대일 할당을 통해 예측을 인스턴스와 매칭한 다음, 예측된 카테고리 점수를 인스턴스 라벨로 대체하여 분류 오류가 없는 $AP^{val}_{w / o c }$를 얻었으며, 유사하게 예측된 위치를 인스턴스의 위치로 대체하여 회귀 오류가 없는 $AP^{val}_{w / o r }$을 얻었습니다. 표 6에서 볼 수 있듯이, $AP^{val}_{w / o r }$ 회귀 오류가 없는 경우가 분류 오류가 없는 경우보다 훨씬 높으며, 회귀 오류를 제거하면 더 큰 개선을 이룰 수 있음을 알 수 있습니다. 따라서 성능 병목은 주로 회귀 작업에 있으며, 경량화된 분류 헤드를 채택함으로써 성능 저하 없이 효율성을 높일 수 있습니다.
- **공간-채널 분리 다운샘플링(Spatial-channel decoupled downsampling)**
우리는 효율성을 위해 다운샘플링 작업을 분리했으며, 채널 차원은 먼저 포인트와이즈 컨볼루션(PW)으로 증가시키고, 해상도는 깊이별 컨볼루션(DW)으로 감소시켜 최대한 정보를 유지합니다. 우리는 이를 표 5의 #3에 있는 YOLOv10-S를 기반으로, DW에 의한 공간 축소 후 PW에 의한 채널 변조를 수행하는 기본 방식과 비교했습니다. 표 7에서 볼 수 있듯이, 우리의 다운샘플링 전략은 다운샘플링 중 정보 손실을 줄임으로써 0.7% AP 개선을 달성했습니다.
- **컴팩트 인버티드 블록(Compact inverted block, CIB)**
우리는 컴팩트한 기본 빌딩 블록으로 CIB를 도입했습니다. 표 5의 #4에 있는 YOLOv10-S를 기반으로 그 효과를 검증했습니다. 구체적으로, 우리는 기준 모델로 인버티드 레지듀얼 블록(IRB)을 도입했으며, 이는 표 8에서 43.7% AP라는 아쉬운 성능을 달성했습니다. 그 후, IRB 뒤에 3×3 깊이별 컨볼루션(DW)을 추가한 "IRB-DW"라는 모델을 도입했으며, 이는 0.5% AP 개선을 가져왔습니다. "IRB-DW"와 비교했을 때, CIB는 또 다른 DW를 최소한의 오버헤드로 추가하여 0.3% AP 개선을 달성하며, CIB의 우수성을 입증했습니다.
- **랭크 기반 블록 설계(Rank-guided block design)**
우리는 모델 효율성을 향상시키기 위해 컴팩트한 블록 설계를 적응적으로 통합하는 랭크 기반 블록 설계를 도입했습니다. 우리는 이를 표 5의 #3에 있는 YOLOv10-S를 기반으로 그 이점을 검증했습니다. 내재적 랭크에 따라 오름차순으로 정렬된 스테이지는 Stage 8-4-7-3-5-1-6-2이며, 이는 그림 3.(a)와 유사합니다. 표 9에서 볼 수 있듯이, 각 스테이지에서 병목 블록을 효율적인 CIB로 점진적으로 교체할 때, Stage 7부터 성능 저하가 발생했습니다. 내재적 랭크가 낮고 중복성이 더 많은 Stage 8과 4에서는 성능 저하 없이 효율적인 블록 설계를 채택할 수 있었습니다. 이러한 결과는 랭크 기반 블록 설계가 모델 효율성을 높이기 위한 효과적인 전략으로 작용할 수 있음을 나타냅니다.

### **5.3.5 정확성 중심 모델 설계를 위한 분석**

우리는 YOLOv10-S/M을 기반으로 정확성 중심 설계 요소들을 점진적으로 통합한 결과를 제시합니다. 우리의 기준 모델은 효율성 중심 설계가 통합된 YOLOv10-S/M 모델입니다(표 2의 #3/#7). 표 10에서 볼 수 있듯이, 대형 커널 컨볼루션과 PSA 모듈을 도입한 결과, YOLOv10-S에서 각각 0.4% AP와 1.4% AP의 상당한 성능 개선이 이루어졌으며, 지연 시간은 각각 0.03ms와 0.15ms로 최소한만 증가했습니다. YOLOv10-M에는 대형 커널 컨볼루션이 적용되지 않았음을 유의하십시오(표 12 참조).

- **대형 커널 컨볼루션(Large-kernel convolution)**
우리는 표 10의 #2에 있는 YOLOv10-S를 기반으로 다양한 커널 크기의 영향을 조사했습니다. 표 11에서 볼 수 있듯이, 성능은 커널 크기가 증가할수록 개선되었으며, 7×7 커널 크기에서 성능이 정체되는 것을 확인할 수 있었습니다. 이는 넓은 수용 영역의 이점을 나타냅니다. 또한, 훈련 중에 재구성 분기를 제거하면 0.1% AP 저하가 발생하며, 이는 최적화에 효과적임을 보여줍니다. 더불어, 우리는 YOLOv10-N / S / M을 기반으로 모델 크기별 대형 커널 컨볼루션의 이점을 조사했습니다. 표 12에서 볼 수 있듯이, YOLOv10-M과 같은 대형 모델에서는 내재적 광범위 수용 영역 때문에 개선이 이루어지지 않았습니다. 따라서, 우리는 대형 커널 컨볼루션을 소형 모델, 즉 YOLOv10-N / S에만 적용합니다.
- **부분 자기 주의(Partial self-attention, PSA)**
PSA는 최소한의 비용으로 글로벌 모델링 능력을 통합하여 성능을 향상시키기 위해 도입되었습니다. 우리는 이를 표 10의 #3에 있는 YOLOv10-S를 기반으로 그 효과를 검증했습니다. 구체적으로, 우리는 기준 모델로 트랜스포머 블록(즉, MHSA 및 FFN)을 도입했으며, 이를 "Trans."로 표시했습니다. 표 13에서 볼 수 있듯이, PSA는 0.05ms의 지연 시간 감소와 함께 0.3% AP 개선을 가져왔습니다. 이러한 성능 향상은 주의 헤드의 중복성을 완화하여 자기 주의에서 발생하는 최적화 문제를 완화한 덕분일 수 있습니다. 또한, 우리는 NPSA의 영향을 조사했습니다. 표 13에서 볼 수 있듯이, NPSA를 2로 증가시키면 0.1ms의 지연 시간 오버헤드와 함께 0.2% AP 개선이 이루어졌습니다. 따라서, 우리는 효율성을 유지하면서 모델 능력을 향상시키기 위해 기본적으로 NPSA를 1로 설정합니다.

# 6. 결론 (Conclusion)

이 논문에서 우리는 YOLO의 탐지 파이프라인 전반에 걸쳐 후처리와 모델 아키텍처를 모두 개선하는 것을 목표로 했습니다. 후처리 측면에서는 NMS(비최대 억제) 없는 훈련을 위해 일관된 이중 할당 전략을 제안하여 효율적인 엔드 투 엔드 객체 탐지를 달성했습니다. 모델 아키텍처 측면에서는 성능-효율성 트레이드오프를 개선하기 위한 전체적인 효율성-정확성 중심 모델 설계 전략을 도입했습니다. 이러한 접근 방식을 통해 새로운 실시간 엔드 투 엔드 객체 탐지기인 YOLOv10을 개발했습니다. 광범위한 실험 결과, YOLOv10이 다른 최신 탐지기들과 비교하여 최첨단 성능과 낮은 지연 시간을 달성했으며, 그 우수성을 잘 입증했습니다.

</div></div>


</div> 
</details>

# Abstract (초록)

지난 몇 년간, YOLO는 **계산 비용과 탐지 성능 간의 균형**을 효과적으로 맞추며 실시간 객체 탐지 분야에서 지배적인 패러다임으로 자리 잡았습니다. 연구자들은 YOLO의 아키텍처 디자인, 최적화 목표, 데이터 증강 전략 등을 탐구하여 상당한 진전을 이루었습니다.

그러나 다음과 같은 **문제점**들이 있습니다:

- **비최대 억제(NMS)에 의존하는 후처리 과정**은 YOLO의 엔드 투 엔드 배포를 저해하고, 추론 지연에 부정적인 영향을 미침.
- YOLO의 **구성 요소 설계에 대한 종합적 검토 부족**으로 인해 계산 중복이 두드러지며, 모델의 능력을 제한하여 비효율성을 초래하고 성능 향상의 잠재력을 제한.

**본 연구의 목표**는:

- YOLO의 **성능-효율성 경계를 후처리와 모델 아키텍처 양측에서 향상**시키는 것.

이를 위해 다음과 같은 **방법**을 제안했습니다:

- **NMS 없는 훈련**을 위한 **일관된 이중 할당 전략**을 제시하여, 경쟁력 있는 성능과 낮은 추론 지연 시간을 동시에 제공.
- YOLO의 **효율성-정확성 중심 모델 설계 전략**을 통해 다양한 구성 요소를 최적화하고 계산 오버헤드를 줄임.

**결과**:

- 새로운 YOLO 시리즈인 **YOLOv10 개발**.
- 광범위한 실험을 통해 YOLOv10이 다양한 모델 스케일에서 **최첨단 성능과 효율성**을 달성함을 확인.
- 예를 들어, **YOLOv10-S**는 유사한 COCO AP 성능을 유지하면서 **RT-DETR-R18보다 1.8배 더 빠르고**, 파라미터와 FLOPs 수가 **2.8배 적음**.
- **YOLOv9-C**와 비교했을 때, **YOLOv10-B**는 성능이 동일한 상태에서 **지연 시간이 46% 감소**하고, **파라미터 수는 25% 감소**.

---

# Introduction (소개)

### 실시간 객체 탐지의 중요성 및 YOLO의 역할

- **연구 배경**:
    - 실시간 객체 탐지는 컴퓨터 비전에서 중요한 연구 주제로, 자율주행, 로봇 내비게이션, 객체 추적 등의 다양한 실제 응용 분야에서 사용됨.
    - 연구자들은 CNN 기반 객체 탐지기 설계에 집중해 왔으며, 그 중 YOLO는 **성능과 효율성 사이의 뛰어난 균형** 덕분에 인기를 얻음.

### YOLO의 탐지 파이프라인 및 문제점

- **탐지 파이프라인**:
    - YOLO는 **모델 FP 처리**와 **NMS 후처리**의 두 부분으로 구성됨.
    - 두 부분 모두 결함이 있어 **최적의 정확도-지연 경계에 도달**하는 데 어려움이 있음.
- **NMS 의존성 문제**:
    - YOLO는 훈련 중 **일대다 레이블 할당 방식**을 사용하여, 성능은 우수하나 **NMS가 필요**함.
    - NMS는 추론 속도를 저하시킬 뿐 아니라, **YOLO의 최적 엔드 투 엔드 배포를 방해**함.
    - DETR 아키텍처를 활용한 방법은 실시간 응용 분야로 확장 가능하지만, 복잡한 배포로 인해 **정확성과 속도 사이의 최적 균형을 달성하기 어려움**.

### 모델 아키텍처 설계의 도전 과제

- **설계 문제**:
    - YOLO의 **모델 아키텍처 설계**는 여전히 근본적인 도전 과제로, **정확도와 속도**에 중요한 영향을 미침.
    - 연구자들은 **다양한 설계 전략**을 탐구해 왔으며, DarkNet, CSPNet, EfficientRep, ELAN 등이 백본의 기능 추출 능력을 향상시키기 위해 제안됨.
    - Neck에서는 PAN, BiC, GD, RepGFPN 등의 기법이 다중 스케일 기능 융합을 향상시키기 위해 탐구됨.
    - **모델 스케일링 전략**과 **재구성 기법**도 조사됨.
- **한계점**:
    - 이러한 노력에도 불구하고, YOLO의 다양한 구성 요소에 대한 **종합적 검토**가 부족하여, **계산 중복**이 존재하고 비효율적인 파라미터 활용으로 인해 **최적의 효율성**을 제한함.
    - 결과적으로 모델의 능력이 제한되어 **정확도 향상의 가능성**이 남아 있음.

---

# Related Work (관련 연구)

### 3.1 실시간 객체 탐지기

- **목표**: 실시간 객체 탐지는 **낮은 지연 시간 내에 객체를 분류하고 위치를 파악**하는 것을 목표로 하며, 이는 실제 응용 프로그램에서 매우 중요합니다.
- **연구 동향**:
    - 최근 몇 년간 **효율적인 탐지기 개발**을 위한 상당한 노력이 이루어졌습니다.
    - 특히 **YOLO 시리즈**는 주류 탐지기로서 두각을 나타내고 있습니다.
- **YOLO 시리즈의 발전**:
    - **YOLOv1, YOLOv2, YOLOv3**: 백본, 넥, 헤드라는 세 부분으로 구성된 전형적인 탐지 아키텍처로 식별됨.
    - **YOLOv4, YOLOv5**: 다크넷(DarkNet)을 대체하기 위해 **CSPNet 설계 도입** 및 다양한 **데이터 증강 전략**과 모델 스케일 추가.
    - **YOLOv6**: 넥과 백본에 **BiC와 SimCSPSPPF 도입**, 앵커 기반 학습 및 **자기 증류 전략** 채택.
    - **YOLOv7**: **E-ELAN 도입** 및 여러 학습 가능한 기법 탐구.
    - **YOLOv8**: **C2f 빌딩 블록 도입**으로 효과적인 특징 추출 및 융합 수행.
    - **Gold-YOLO**: **고급 GD 메커니즘**으로 다중 스케일 특징 융합 기능 강화.
    - **YOLOv9**: 아키텍처 개선을 위해 **GELAN** 제안, 학습 과정에서 **PGI 도입**.

### 엔드 투 엔드 객체 탐지기

- **엔드 투 엔드 객체 탐지**:
    - 전통적인 파이프라인에서 벗어나, **간소화된 아키텍처**를 제공하여 탐지 분야에서 패러다임 전환을 일으킴.
- **DETR 아키텍처**:
    - **트랜스포머 아키텍처**를 도입하고, **헝가리안 손실**을 채택하여 **일대일 매칭 예측** 실현.
    - 수작업 구성 요소와 후처리를 제거하여 탐지 효율성 향상.
- **DETR 변형 모델**:
    - **Deformable-DETR**: 멀티 스케일 변형 가능한 주의 모듈 활용으로 **수렴 속도 가속화**.
    - **DINO**: 대조적 디노이징, 쿼리 선택 혼합, 두 번 보기 스킴을 통합하여 성능 향상.
    - **RT-DETR**: **효율적인 하이브리드 인코더** 설계, **불확실성을 최소화한 쿼리 선택**으로 정확성과 지연 시간 향상.
- **CNN 기반 탐지기**:
    - **학습 가능한 NMS와 관계 네트워크**: 중복된 예측 제거를 위한 또 다른 네트워크 제공.
    - **OneNet, DeFCN**: **일대일 매칭 전략**을 통해 완전히 컨볼루션 네트워크로 **엔드 투 엔드 객체 탐지** 가능.
    - **FCOSpss**: 예측을 위한 **최적의 샘플 선택**을 위해 긍정적 샘플 선택기 도입.

---

# Methodology (방법론)

### 4.1 NMS-Free 훈련을 위한 일관된 이중 할당 전략

- NMS
    
    ### **NMS의 과정**
    
    1. 모든 Bounding box는 자신이 해당 객체를 얼마나 잘 잡아내지 나타내는 confidence score를 가집니다. 모든 bounding box에 대하여 **threshold 이하의 confidence score를 가지는 Bounding Box는 제거**합니다. Confidence score가 일정 수준 이하인 bounding box들에 대해 일차적으로 필터링을 거치는 과정입니다.
    2. 남은 Bounding Box들을 Confidence score 기준 모두 **내림차순 정렬**합니다.
    3. 맨 앞에 있는 Bounding box 하나를 기준으로 잡고, 다른 bounding box와 IoU 값을 구합니다. **IoU가 threshold 이상**인 Bounding box들은 제거합니다. Bounding box끼리 IoU가 높을수록, 즉 많이 겹쳐질수록 같은 물체를 검출하고 있다고 판단하기 때문입니다.
    4. 해당 과정을 순차적으로 시행하여 모든 Bounding box를 비교하고 제거합니다.
    5. **Confidense threshold가 높을수록, IoU threshold가 낮을수록 더 많은 bounding box가 제**거됩니다.

![images/Yolov10 review images/Untitled.png](/img/user/images/Yolov10%20review%20images/Untitled.png)
(a) NMS가 필요 없는 훈련을 위한 일관된 이중 할당. 
(b) 기본적으로 $\alpha_{o2m}=0.5$ 및 $\beta_{o2m}=6$ 을 사용하는 YOLOv8-S에서 일대다 결과의 상위 1/5/10에서 일대일 할당 빈도 [20]. 일관성을 위해, $\alpha_{o2o}=0.5$ $\alpha_{o2o}=0.5$$\beta_{o2o}=6$ (r =1 )
일관성 없는 경우, $\alpha_{o2o}=0.5$; $\beta_{o2o}=2$ ](Untitled.png)

**그림 2** : (a) NMS가 필요 없는 훈련을 위한 일관된 이중 할당. 
(b) 기본적으로 $\alpha_{o2m}=0.5$ 및 $\beta_{o2m}=6$ 을 사용하는 YOLOv8-S에서 일대다 결과의 상위 1/5/10에서 일대일 할당 빈도 [20]. 일관성을 위해, $\alpha_{o2o}=0.5$ $\alpha_{o2o}=0.5$$\beta_{o2o}=6$ (r =1 )
일관성 없는 경우, $\alpha_{o2o}=0.5$; $\beta_{o2o}=2$ 

### **이중 레이블 할당 (Dual label assignments)**

- **기존 문제**:
    - YOLO는 훈련 중 다수의 긍정 샘플을 할당하는 방식(일대다)을 채택하여, 풍부한 지도 신호를 제공하고 성능을 향상시킬 수 있음.
    - 그러나, 이 방식은 YOLO가 비최대 억제(NMS) 후처리에 의존하게 하여, **추론 성능과 효율성을 저해**.
- **새로운 접근법**:
    - 이중 레이블 할당을 도입하여 **일대다 할당과 일대일 할당의 장점을 결합**.
    - 훈련 중, YOLO에 일대일 헤드를 추가하여 다중 할당과 동일한 최적화 목표를 달성함.
    - **추론 중에는 일대일 헤드만 사용**하여 추가적인 추론 비용 없이 엔드 투 엔드 배포 가능.

### **일관된 매칭 메트릭 (Consistent matching metric)**

- **목적**:
    - 일대다와 일대일 할당 방식 모두에서 예측과 인스턴스 간의 일치 정도를 정량적으로 평가하기 위해, **일관된 매칭 메트릭** 도입. ⇒ 매칭 메트릭은 각각(o2o, o2m)의 예측이 실제 객체와 얼마나 잘 맞는지를 평가하는 데 사용
- **수식**:
    - 매칭 메트릭: $m(\alpha, \beta) = s \cdot p^\alpha \cdot \text{IoU}(\hat{b}, b)^\beta$
    - 여기서 $p$는 분류 점수, $\hat{b}$와 $b$는 각각 예측과 인스턴스의 바운딩 박스, $s$는 예측의 앵커 포인트가 인스턴스 내에 있는지 여부를 나타냄.
    - $\alpha$와 $\beta$는 의미 예측 작업과 위치 회귀 작업의 영향을 균형 있게 조절하는 중요한 하이퍼파라미터
    - 다중 할당 메트릭: $m_{\text{o2m}} = m(\alpha_{\text{o2m}}, \beta_{\text{o2m}})$
    - 일대일 메트릭: $m_{\text{o2o}} = m(\alpha_{\text{o2o}}, \beta_{\text{o2o}})$
- **결과**:
    - 일대일 헤드와 일대다 헤드 간의 지도 신호 차이를 줄이기 위해, 일관된 매칭 메트릭을 사용.
    - 일대일 헤드는 일대다 헤드에 비해 학습 시의 수렴효과 및 정확도가 떨어지는 것으로 보임.
    - 학습 시에는 일대다 헤드와 일대일 헤드를 모두 사용하여 같이 최적화 함으로써 높은 학습효과를 기대
    - 추론 중에는 일대일 헤드만 사용하여 빠른 추론이 가능하도록 함
    - $\alpha_{o2o} = r \cdot \alpha_{o2m} 및 \beta_{o2o} = r \cdot \beta_{o2m}$로 설정하여, 일대다 헤드에서 최고의 긍정 샘플이 일대일 헤드에서도 최고의 샘플이 되도록 함.
    - $r=1$(o2o와 o2m의 조화 비율)일 때, 두 헤드는 **일관되고 조화롭게 최적화**될 수 있음.
    $r$은 일대일 할당 메트릭과 일대다 할당 메트릭사이의 관계를 조절하여, 두 메트릭이 서로 얼마나 일치할지를 결정
    - $r>1$: o2o의 매칭 메트릭에서 $\alpha$와 $\beta$ 값이 더 커지게 됩니다. **이는 o2o 할당에서 분류 점수와 IoU의 중요도를 더 크게 반영하게 되어, 일대일 매칭에서 더 엄격한 기준을 적용하는 효과**를 가집니다.
    - $r<1$: o2o의 매칭 메트릭에서 $\alpha$와 $\beta$ 값이 더 작아지게 됩니다. **이는 o2o 할당에서 분류 점수와 IoU의 중요도를 상대적으로 낮추어, 일대다 매칭과의 조화를 더 중시하는 방향으로 조정**됩니다.
    - **일관된 매칭 메트릭 사용 시, 훈련 후 일대다 결과의 Top 1/5/10 내에서 일대일 매칭 쌍의 수가 증가**함을 그림 2.(b)에서 확인.

### 4.2 전반적인 효율성-정확성 중심의 모델 설계

![images/Yolov10 review images/Untitled 1.png](/img/user/images/Yolov10%20review%20images/Untitled%201.png)
(a) YOLOv8에서 스테이지와 모델 전반에 걸친 고유 랭크. 백본과 넥의 스테이지는 모델의 순방향 처리 순서에 따라 번호가 매겨져 있습니다. 수치 랭크  $r$은 y축에서 $r/C_o$로 정규화되며, 임계값은 기본적으로 $λ_{max}/2$로 설정됩니다. 여기서 $C_o$는 출력 채널 수를 나타내고, $λ_{max}$는 가장 큰 특이값을 의미합니다. 깊은 스테이지와 큰 모델이 더 낮은 고유 랭크 값을 나타냅니다. 
(b) 컴팩트 인버티드 블록(CIB). 
(c) 부분 자기 주의 모듈(PSA).](Untitled%201.png)

그림 3. (a) YOLOv8에서 스테이지와 모델 전반에 걸친 고유 랭크. 백본과 넥의 스테이지는 모델의 순방향 처리 순서에 따라 번호가 매겨져 있습니다. 수치 랭크  $r$은 y축에서 $r/C_o$로 정규화되며, 임계값은 기본적으로 $λ_{max}/2$로 설정됩니다. 여기서 $C_o$는 출력 채널 수를 나타내고, $λ_{max}$는 가장 큰 특이값을 의미합니다. 깊은 스테이지와 큰 모델이 더 낮은 고유 랭크 값을 나타냅니다. 
(b) 컴팩트 인버티드 블록(CIB). 
(c) 부분 자기 주의 모듈(PSA).

- **도전 과제**:
    - YOLO 모델의 아키텍처는 **효율성과 정확성 간의 트레이드오프**를 해결하는 데 큰 어려움을 겪고 있음.
    - 다양한 설계 전략이 연구되었지만, YOLO의 구성 요소에 대한 **종합적인 검토**가 부족하여 **계산적 중복성과 제한된 능력**을 나타냄.
- **목표**:
    - **효율성과 정확성**을 중심으로 YOLO 모델을 **전반적으로 설계**하여, 효율성과 성능을 모두 최적화.

### **효율성 중심 모델 설계**

- **구성 요소**:
    - **다운샘플링 레이어(downsampling layers)**, **기본 빌딩 블록이 포함된 스테이지(stages with basic building blocks)**, **헤드(head)**로 구성.
1. **경량 분류 헤드(Lightweight classification head)**:
    - **차이점**: YOLO 모델에서 Classification 헤드와 Regression 헤드는 동일한 구조를 공유하지만, 계산 오버헤드에서 큰 차이를 보임.
    - **경량화 방법**: 분류 헤드의 오버헤드를 줄이기 위해 **커널 크기 3×3의 Depth-wise 컨볼루션**과 **1×1 컨볼루션(Point-wise Conv)**으로 구성된 경량 아키텍처를 채택.
2. **공간-채널 분리 다운샘플링(Spatial-channel decoupled downsampling)**:
    - **기존 방법**: 3×3 표준 컨볼루션을 스트라이드 2로 활용하여 **공간 다운샘플링**과 **채널 변환**을 동시에 수행.
    - **새로운 접근**: 공간 감소와 채널 증가 작업을 **분리**하여, **Point-wise Conv**으로 채널 차원을 조절하고,  **Depth-wise Conv**으로 공간 다운샘플링을 수행. 이를 통해 **계산 비용**과 **파라미터 수**를 줄이고 **성능과 지연 시간**을 개선.
3. **랭크 기반 블록 설계(Rank-guided block design)**:
    - **문제점**: YOLO 모델은 모든 스테이지(layer를 그룹화)에 동일한 기본 빌딩 블록을 사용하여 **최적의 성능-효율성 트레이드오프**를 달성하지 못함.
    - **해결책**: **고유 랭크(intrinsic rank)**를 활용하여 각 스테이지의 중복성을 분석하고, **컴팩트 인버티드 블록(CIB)** 구조를 제안. 고유 랭크에 따라 스테이지를 정렬하고, 중복성이 많은 스테이지에 대해 복잡성을 줄인 블록 설계.
    - 고유 랭크 계산
        
        ### 고유 랭크(Intrinsic Rank) 계산 방법
        
        1. **특정 계층의 가중치 행렬 선택**:
            - 고유 랭크를 계산하기 위해, YOLOv10의 특정 스테이지나 계층의 **가중치(weight) 행렬**을 선택합니다. 주로 **마지막 기본 블록**에서 **마지막 컨볼루션 층**의 가중치 행렬이 사용됩니다.
        2. **특이값 분해(SVD, Singular Value Decomposition)**:
            - 선택된 가중치 행렬에 대해 **특이값 분해(SVD)**를 수행합니다. 특이값 분해는 행렬을 세 개의 행렬(왼쪽 특이 벡터 행렬, 대각 특이값 행렬, 오른쪽 특이 벡터 행렬)로 분해하여, 해당 행렬의 중요한 성분을 추출하는 방법입니다.
            - SVD의 결과로 나오는 대각 특이값 행렬에서 **특이값(singular values)**은 행렬의 각 차원별 정보의 중요도를 나타냅니다.
        3. **특이값의 임계값 결정**:
            - 특이값 분해 결과에서, **임계값(threshold)**을 설정하여, 그 이상의 특이값만을 유지합니다. 임계값은 일반적으로 특이값 중 **가장 큰 특이값 $λmax$ 의 절반 $\frac{λmax}2$으로 설정됩니다.
            - 이 임계값을 기준으로 **유의미한 정보**를 포함하는 특이값을 선택하고, 그 개수를 셉니다.
        4. **고유 랭크 계산**:
            - 위에서 설정한 임계값 이상을 가지는 특이값의 수가 해당 계층 또는 스테이지의 **고유 랭크**입니다. 이 값은 모델이 해당 계층에서 표현할 수 있는 정보의 복잡도를 나타냅니다.
            - **고유 랭크가 낮을수록 해당 계층이 표현하는 정보가 덜 복잡하고, 중복성이 많다는 것을 의미합니다.**

### **정확성 중심 모델 설계(Accuracy driven model design)**

- **목표**: **비용을 최소화하면서 성능을 극대화**하기 위해 대형 커널 컨볼루션과 self-attention를 탐구.
1. **대형 커널 컨볼루션(Large-kernel convolution)**:
    - **이점**: **수용 영역을 확장하여 모델의 능력을 향상시키는 효과적인 방법.**
    - **적용 범위**: 모든 스테이지에 적용하는 대신, **깊은 스테이지**에서 **CIB의 두 번째 3×3 깊이별 컨볼루션**의 커널 크기를 7×7로 증가시켜 사용.
    장점 : 더 많은 영역의 정보를 고려할 수 있음 ⇒ **더 복잡한 패턴**과 **더 높은 수준의 특징**을 추출 가능
    단점 : 학습에서만 7x7 커널을 사용하고 추론에서는 3x3 사용(구조적 재파라미터화) ⇒ **모델의 복잡성을 관리**하고 **효율성**을 유지
    - **작은 모델** 크기에만 대형 커널 컨볼루션을 적용 ⇒ 모델이 커질수록 자연스럽게 커널의 크기도 커지기 때문
2. **부분 self-attention(Partial self-attention, PSA)**:
    - **문제점**: **self-attention**는 높은 계산 복잡성과 메모리 사용량이 큼.
    - **해결책**: attention 헤드의 중복성을 줄이기 위해 **효율적인 부분 자기 주의(PSA) 모듈**을 설계. 1×1 컨볼루션 이후 채널을 두 부분으로 분할하고, 한 부분만을 MHSA와 FFN으로 구성. PSA는 **가장 낮은 해상도의 스테이지 4 이후에만 배치**하여 오버헤드를 줄임.

---

# Experiments (실험)

### 5.1 구현 세부사항

- **YOLOv8 선택 이유**: 뛰어난 지연 시간-정확도 균형 및 다양한 모델 크기 제공.
- **모델 설계**: NMS가 필요 없는 훈련을 위한 **일관된 이중 할당 전략**을 사용하여 **YOLOv10** 모델 설계.
- **모델 변형**: YOLOv8과 동일한 **N / S / M / L / X 변형**을 가짐, YOLOv10-M의 너비 스케일 팩터를 증가시켜 **YOLOv10-B**를 도출.
- **검증**: COCO 데이터셋에서 초기 학습 설정을 통해 탐지기 검증, **T4 GPU에서 TensorRT FP16**으로 지연 시간 테스트.

### 최신 기술과의 비교

![표 1: 최신 기술들과의 비교. 지연 시간은 공식적으로 사전 훈련된 모델을 사용하여 측정되었습니다. $Latency^f$는 후처리 없이 모델의 순방향 처리 과정에서의 지연 시간을 나타냅니다. $†$는 NMS를 사용하는 원래의 일대다 훈련을 통해 얻은 YOLOv10의 결과를 의미합니다. 공정한 비교를 위해, 아래의 모든 결과는 지식 증류나 PGI와 같은 추가적인 고급 훈련 기술을 사용하지 않았습니다.](/img/user/images/Untitled 2.png)

표 1: 최신 기술들과의 비교. 지연 시간은 공식적으로 사전 훈련된 모델을 사용하여 측정되었습니다. $Latency^f$는 후처리 없이 모델의 순방향 처리 과정에서의 지연 시간을 나타냅니다. $†$는 NMS를 사용하는 원래의 일대다 훈련을 통해 얻은 YOLOv10의 결과를 의미합니다. 공정한 비교를 위해, 아래의 모든 결과는 지식 증류나 PGI와 같은 추가적인 고급 훈련 기술을 사용하지 않았습니다.

- **YOLOv10 성능**: 다양한 모델 크기에서 **최첨단 성능**과 **엔드 투 엔드 지연 시간** 달성.
- **YOLOv8과 비교**:
    - **AP 개선**: 1.2% ~ 1.4% 개선.
    - **파라미터 감소**: 28% ~ 57% 감소.
    - **계산 감소**: 23% ~ 38% 감소.
    - **지연 시간 감소**: 37% ~ 70% 감소.
- **다른 YOLO 모델들과 비교**:
    - YOLOv10-N / S는 YOLOv6-3.0-N / S보다 각각 1.5 AP, 2.0 AP 더 우수.
    - YOLOv10-B / M은 YOLOv9-C / YOLO-MS보다 지연 시간이 각각 46%, 62% 감소.
    - YOLOv10-L은 Gold-YOLO-L보다 파라미터가 68% 적고, 지연 시간이 32% 감소, AP 1.4% 개선.
- **RT-DETR과 비교**: YOLOv10-S / X는 RT-DETR-R18 / R101보다 1.3배 ~ 1.8배 빠른 추론 속도를 달성.

### 5.3 모델 분석

### **5.3.1 절충 연구(Ablation study)**

- **YOLOv10-S의 절충 결과**:
    - **지연 시간 감소**: NMS 없는 훈련으로 YOLOv10-S의 엔드 투 엔드 지연 시간이 4.63ms 감소.
    - **효율성 개선**: 효율성 중심 모델 설계로 11.8M 파라미터, 20.8 GFLOPs 감소.
    - **정확도 개선**: 정확도 중심 모델 설계로 YOLOv10-S / M의 AP가 각각 1.8, 0.7 증가, 지연 시간 오버헤드는 0.18ms, 0.17ms.

### **5.3.2 NMS-Free 훈련을 위한 분석**

- **이중 레이블 할당**:
    - 훈련 시 일대다(o2m) 분기의 풍부한 지도 신호와 추론 시 일대일(o2o) 분기의 높은 효율성을 결합.
    - 이중 레이블 할당 방식은 **최고의 AP(Average Precision(평균 정밀도))-지연 시간 트레이드오프** 달성.
- **일관된 매칭 메트릭**:
    - **일대일 헤드와 일대다 헤드** 간의 조화를 위해 일관된 매칭 메트릭 도입.
    - $α_{o2o}=r·α_{o2m}$ 및 $β_{o2o}=r·β_{o2m}$으로 설정하여 최적의 성능 달성.

### **5.3.4 효율성 중심 모델 설계를 위한 분석**

- **경량화된 분류 헤드**:
    - **카테고리 및 위치 오류 분석**: 회귀 오류를 제거하면 성능이 크게 개선됨, 성능 병목은 주로 회귀 작업에 있음.
    - **효율성**: 경량화된 분류 헤드 채택으로 성능 저하 없이 효율성 향상.
- **공간-채널 분리 다운샘플링**:
    - **효율적 다운샘플링 전략**: 정보 손실을 줄여 0.7% AP 개선 달성.
- **컴팩트 인버티드 블록(CIB)**:
    - **효과 검증**: CIB 도입으로 0.3% AP 개선, 효율성 향상.
- **랭크 기반 블록 설계**:
    - **내재적 랭크 기반 정렬**: 중복성이 많은 스테이지에 효율적인 블록 설계 적용, 모델 효율성 향상.

### **5.3.5 정확성 중심 모델 설계를 위한 분석**

- **대형 커널 컨볼루션**:
    - **커널 크기 영향 조사**: 커널 크기가 증가할수록 성능 개선, 작은 모델에만 대형 커널 컨볼루션 적용.
- **부분 자기 주의(PSA)**:
    - **효율적 성능 향상**: PSA 도입으로 지연 시간 감소 및 AP 개선, NPSA를 1로 설정하여 모델 효율성 유지.

---

## Conclusion (결론)

![images/Yolov10 review images/Untitled 2.png](/img/user/images/Yolov10%20review%20images/Untitled%202.png)

그림 1: 지연 시간-정확도(왼쪽) 및 크기-정확도(오른쪽) 트레이드오프 측면에서 다른 모델들과의 비교. 우리는 공식적으로 사전 훈련된 모델을 사용하여 엔드 투 엔드 지연 시간을 측정했습니다.

이 논문에서는 **YOLO의 탐지 파이프라인 전반**에서 **후처리**와 **모델 아키텍처**를 모두 개선하는 것을 목표로 했습니다.

- **후처리 측면**에서는, **NMS(비최대 억제) 없는 훈련**을 위해 **일관된 이중 할당 전략**을 제안하여 **효율적인 엔드 투 엔드 객체 탐지**를 달성했습니다.
- **모델 아키텍처 측면**에서는, **성능-효율성 트레이드오프**를 개선하기 위한 **효율성-정확성 중심 모델 설계 전략**을 도입했습니다.

이러한 접근 방식을 통해 **새로운 실시간 엔드 투 엔드 객체 탐지기 YOLOv10**을 개발했습니다.

광범위한 실험 결과, **YOLOv10**은 다른 최신 탐지기들과 비교하여 **최첨단 성능**과 **낮은 지연 시간**을 달성했으며, 그 우수성이 입증되었습니다.