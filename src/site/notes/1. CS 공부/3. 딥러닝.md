---
{"dg-publish":true,"permalink":"/1-cs/3/","created":"2025-03-04T13:16:46.680+09:00","updated":"2025-03-13T15:40:45.556+09:00"}
---

## 딥러닝이란? 딥러닝과 머신러닝의 차이

- 딥러닝: **여러 층을 가진 인공신경망(ANN)을 사용하여 머신러닝 학습을 수행**하는 것, 심층학습이라고도 한다.
	딥러닝은 머신러닝에 포함되는 개념이다.
	![Pasted image 20250304132404.png](/img/user/images/Pasted%20image%2020250304132404.png)
	
	- 머신러닝과 딥러닝 차이점
		특징 추출 단계에서 **사람이 직접 분석하고 판단**하면 &rarr; 머신러닝
		특징 추출 단계에서 **기계가 자동으로 판단**하면 &rarr; 딥러닝
		
		정형데이터는 주로 머신러닝, 비정형 데이터는 주로 딥러닝에서 사용된다.

---
## Cost Function과 Activate Function

- **Cost function**: 모델이 데이터에 대해 현재 예측을 얼마나 잘하고 있는지 알아야 학습 방향을 어느 방향으로, 얼마나 개선할지 판단 가능하다.
	
	이때 예측 값과 데이터 값의 차이에 대한 함수를 Cost function(MSE, Cross Entropy 등)이라고 한다.
	
	**Cost function이 최소함으로써 모델을 적절한 표현력을 갖추도록 학습** 시킬 수 있다.

- **Activate function**: 선형 모델만을 사용해서는 복잡한 데이터에 대해 적절한 예측이 불가능할 수 있다. 이를 처리하기 위해 **비선형 모델**이 필요로된다.
	
	**선형 모델을 비선형 모델로 바꿔주는 함수를 Activate function**(ReLU, Sigmoid 등)이라고 한다. 
	
	**비선형 모델은 깊게 쌓을 수 있다.**  이를 통해 더 복잡한 데이터에 대한 표현력이 좋아질 수 있다.

---
## Tensorflow와 Pytorch

|   구분   |    Tensorflow    |      PyTorch      |
| :----: | :--------------: | :---------------: |
|  패러다임  |  Define and Run  |   Define by Run   |
| 그래프 형태 | Static graph(정적) | Dynamic graph(동적) |
-  Tensorflow와 Pytorch의 차이점
	- 패러다임이 다르다
		- Define and Run: 모델 계산 그래프를 먼저 **정의**하고 그 그래프를 따로 세션등을 통해 한 번에 **실행**하는 방식이다. (그래프가 정적)
		- Define by Run: 한 줄 한 줄의 연산을 **실행**하면서 그래프가 동적으로 **정의**되는 방식이다. (그래프가 동적)

| 구분 | Define and Run                                                         | Define byy Run                                                      |
|:---|:-----------------------------------------------------------------------|:--------------------------------------------------------------------|
| 장점 | - 내부 최적화에 유리<br>- 대규모 배초나 모바일/임베디드 환경에서 효율적<br>- 한번 그래프를 확정 지으면 예측이 용이 | - 직관적이고 파이썬스러워 디버깅이 쉽고 학습 곡선이 비교적 낮음<br>- 실행 흐름과 코드가 같아 빠른 프로토타입 가능 |
| 단점 | - 디버깅이 어렵고 유지보수가 어려움<br>- 즉시 결과확인이 어려움                                 | - 그래프 최적화를 위해 추가적인 작업이 필요할 수도 있음<br>- 초기에는 정적 그래프대비 속도가 느림          |  

---
## Data Nomalization

![Pasted image 20250304135502.png](/img/user/images/Pasted%20image%2020250304135502.png)
- **Data Nomalization**: Feature들의 분포(Scale)을 조절하여 균일하게 만드는 방법이다. 
	크기가 큰 feature는 작은 크기를 가지는 feature보다 더 강하게 모델에 영향을 끼칠 수 있기 때문에 사용된다.
	
	따라서 모든 데이터들이 동일한 스케일(중요도)를 반영할 수 있도록 하기위해 사용한다
	- 학습속도 개선
	- 노이즈 감소 &rarr; 오버피팅 억제
	- 데이터가 덜 치우쳐져 좋은 성능을 보임

- **Regularization**: 모델에 제약을 주어 모델의 복잡성을 낮추고 이를 통해 **오버피팅을 방지하는 방법**
	**처음 보는 데이터에도 잘 예측하도록 만드는 방법을** Regularization(일반화)라고 한다.
	Dropout, EarlyStopping, Weight decay, L1,L2와 같은 방법들이 있다.

- Normalization, Standardization: 둘 다 데이터를 축소하는 방법이다.
	- Normalization
		- Batch Nomalization: 적용시키려는 레이어의 통계량, 분포를 정규화시키는 방법이다.
		- Min-Max Normalization: 모든 데이터 중에서 가장 작은 값을 0, 가장 큰 값을 1로 두도록 스케일링하는 방법, 이상치를 잘 처리하지 못한다는 단점이 있다.
			$x = \frac{x - x_{min}}{x_{max} - x_{min}}$
	
	- Standardization: 표준화 확률 변수를 구하는 방법이다. 이는 z-score를 구하는 방법을 의미한다. 따라서 z-score normalization이라고도 불린다.
		- Z-score: 관측값이 평균 기준으로 얼마나 떨어져있는지 나타낼 때 사용한다. 이상치(outlier)를 잘 처리하지만, 정확히 동일한 척도로 정규화 된 데이터를 생성하지는 않는다.
			$z - score = \frac{x - \mu}{\sigma}$

---
## Activation function의 종류 및 특징

- Sigmoid: $S(z) = \frac{1}{1 + e^{-x}}$ 의 수식으로 계산되며 0 ~ 1 사이의 값으로 매핑된다.
	**입력값이 너무 크거나 작으면 기울기가 0에 가까워져 기울기 소실 문제를 야기한다.**
	**zero-centered가 아니기 때문에 부호에 따라 영향을 받아** 경사하강법에서 정확한 방향으로 가지 못하고 **지그재그로 움직이게 된다.**
	![Pasted image 20250304141605.png](/img/user/images/Pasted%20image%2020250304141605.png)

- Tanh: 입력을 -1 ~ 1사이의 값으로 매핑한다. Sigmoid와 유사한 모양을 띄며 동일하게 **기울기 소실 문제가 발생한다.**
	![Pasted image 20250304141716.png](/img/user/images/Pasted%20image%2020250304141716.png)

- ReLU: $f(x) = max(0,x)$의 수식으로 계산된다. 계산 효율과 성능에서 뛰어난 성능을 보여 가장 많이 사용되는 활성화 함수이다. 양의 입력에서는 기울기 소실과 같은 문제가 발생하지 않지만 **음의 입력에서는 기울기가 0이라 어떤 업데이트도 진행되지 않는 Dead ReLU 문제가 발생한다.**
	![Pasted image 20250304142011.png](/img/user/images/Pasted%20image%2020250304142011.png)

- Leaky ReLU: $f(x) = max(0.01x, x)$으로 계산되며 ReLU와 마찬가지로 좋은 성능을 유지하면서 **음의 입력에서도 0이 아니기 때문에 Dead ReLU문제를 해결하였다.**
	![Pasted image 20250304142137.png](/img/user/images/Pasted%20image%2020250304142137.png)


---
## 오버피팅의 경우 어떻게 대처해야하는가

- **Early Stopping**: train loss는 계속 낮아지더라도 validation loss가 올라가는 시점을 오버피팅으로 간주하여 학습을 종료하는 방법이다.
	![Pasted image 20250304142259.png](/img/user/images/Pasted%20image%2020250304142259.png)

- **Parameter Norm Penalty / Weight Decay**: 비용함수에 제곱을 더하거나(L2 정규화) 절대값을 더해서(L1 정규화) weight의 크기에 페널티를 부과하는 방법이다.
	$totalcost=loss(D;W)+\frac{α}{2}‖W‖^2_2$

- **Data Augmentation**: 훈련데이터가 부족할 때 인위적으로 데이터의 양을 늘려 훈련 데이터 수를 늘리는 방법이다.

- **Noise robustness**: 노이즈나 이상치 같은 엉뚱한 데이터가 들어와도 강건한 모델을 만들기 위해 input data나 weight에 일부러 노이즈를 추가하는 방법이다.

- **Label smoothing**: 모델이 정확하게 GT를 예측하지 않아도 되도록 만들어 정확하지 않은 데이터셋에 치중되는 경향(overconfident)을 막아주는 방법이다. &rarr; 기존의 100점이어야 성공이라면 90점이어도 성공으로 쳐준다~

- **Dropout**: 각 계층에서 일정 비율의 뉴런을 임의로 drop시켜 나머지 뉴런만을 통해 학습을 진행하는 방법이다. 이는 학습 과정에서만 사용하고 추론시에는 사용하지 않는다.
	![Pasted image 20250304142936.png](/img/user/images/Pasted%20image%2020250304142936.png)

- **Batch Normalization**: 활성화함수의 활성화값 또는 출력값을 정규화하는 방법이다. **각 hidden layer에서 정규화를 하면서 입력분포가 일정하게 되고**, 이에 따라 Learning rate을 크게 설정해도 괜찮아진다. 결과적으로 학습속도가 빨라지는 효과가 있다.
	![Pasted image 20250304143044.png](/img/user/images/Pasted%20image%2020250304143044.png)

---
## 하이퍼 파라미터란?

- **하이퍼 파라미터: 모델링 진행 시 사용자가 직접 지정해주어야하는 값을 의미**한다.
	정해져있는 최적의 하이퍼 파라미터는 없으며 모델 구조, 데이터 양과 같은 여러가지 요소에 의해 적절한 값이 달라질 수 있다.
	
	Manual Search, Grid Search, Random Search, Bayesian Opimization등의 방법을 통헤 하이퍼 파라미터 튜닝을 할 수 있다.
	![Pasted image 20250304143358.png](/img/user/images/Pasted%20image%2020250304143358.png)

- 딥러닝에서 추천하는 방식은 Random Search 방식이다.
	![Pasted image 20250313152334.png](/img/user/Pasted%20image%2020250313152334.png)
	- **고차원 공간에서의 효율성:**
		- **Grid Search:** 모든 하이퍼파라미터 조합을 격자 형태로 탐색하므로 후보 조합이 기하급수적으로 늘어나 탐색 비용이 큽니다.
		- **Random Search:** 각 파라미터를 무작위로 샘플링하여 전체 탐색 공간을 효율적으로 커버합니다.
	- **중요 하이퍼파라미터 집중:**
		- 일부 파라미터가 모델 성능에 큰 영향을 주는데, Random Search는 이러한 핵심 파라미터의 다양한 값을 효과적으로 탐색할 수 있습니다.

- 파라미터 vs 하이퍼 파라미터: 사람이 직접 설정하느냐 마느냐에 따라 구분된다.
	![Pasted image 20250304143453.png](/img/user/images/Pasted%20image%2020250304143453.png)

> [!용어]
>  - 선험적 지식: 경험하지 않아도 알 수 있는 것을 말한다.
 >  - 휴리스틱: 체계적이면서 합리적인 판단이 굳이 필요하지 않은 상황에서 사람들이 빠르게 사용할 수 있도록, 보다 용이하게 구성된 간편추론의 방법이다. '대충 어림짐작하기', '눈대중으로 맞추기' 등의 방법을 일컫는다.

---
## Weight Initalization

- 가중치 초기화: 기울기 소실이나 local minimum 등의 문제를 일으킬 수 있기 때문에 중요하다.

- LeCun Initialization: 들어오는 노드 수에 대해 정규 분포와 균등 분포를 따르는 방법
	- 정규 분포
		$W \sim N(0, Var(W)), \quad Var(W) = \sqrt{\frac{1}{n_{in}}}$
	- 균등 분포
		$W \sim U(- \sqrt{\frac{1}{n_{in}}}, + \sqrt{\frac{1}{n_{in}}})$

- Xavier Initialization: LeCun 방법과 비슷하지만 들어오는 노드 수와 나가는 노드 수에 의존하고, 적절한 상수값도 발견하여 사용한 방법이다.
	sigmoid 나 tanh 함수와는 좋은 결과를 보여주지만 ReLU 함수와 사용할 경우 0에 수렴하는 문제가 발생한다.  따라서 `sigmoid` 나 `tanh` 함수와 주로 많이 사용한다.
	
	- 정규 분포
		$W \sim N(0, Var(W)), \quad Var(W) = \sqrt{\frac{2}{n_{in} + n_{out}}}$
	- 균등 분포
		$W \sim U(- \sqrt{\frac{6}{n_{in} + n_{out}}}, + \sqrt{\frac{6}{n_{in} + n_{out}}})$

- He Initialization: ReLU 와 함께 많이 사용되는 방법으로, LeCun 방법과 같지만 상수를 다르게 하였다. 들어오는 노드만 고려한다.
	- 정규 분포
		$W \sim N(0, Var(W)), \quad Var(W) = \sqrt{\frac{2}{n_{in}}}$
	- 균등 분포
		$W \sim U(- \sqrt{\frac{6}{n_{in}}}, + \sqrt{\frac{6}{n_{in}}})$

---
## 볼츠만 머신

- 볼츠만 머신: 가시층(Visible Layer)와 은닉층(Hidden Layer), 총 두 개의 층으로 신경망을 구성하는 방법이다.
	모든 뉴런이 연결되어 있는 완전 그래프 형태이며, 제한된 볼츠만 머신(RBM)에서는 같은 층의 뉴런들은 연결되어 있지 않은 모양이다.
	![Pasted image 20250304144257.png](/img/user/images/Pasted%20image%2020250304144257.png)

---
## 뉴럴넷의 가장 큰 단점은 무엇인가

- 사람은 처음 본 물건(레이블)에 대해 구분이 가능하다. 하지만 뉴럴넷은 이 물건을 구분하기 위해 이 물건에 대한 데이터가 필요하다.

- One-shot Learning: 뉴럴넷도 새로운 레이블을 지닌 데이터가 적을 때 (one shot에서는 1개) 에도 모델이 좋은 성능을 내도록 사용하는 방법이다.
	이를 위해서는 다른 레이블의 많은  데이터를 학습한 Pretrained모델이 필요하다.
	학습된 모델에 새로운 레이블의 데이터 하나 던져 주면 모델은 데이터의 특성에 대한 이해를 바탕으로 이 레이블에 대해서도 이해를 하게 된다.

## None-Linearity

- **Linearlity(선형)**: 어떤 모델이 선형적이다 라고 한다면 **그 모델은 변수 $x_1, x_2, ... , x_n$과 가중치 $w_1, w_2, ... , w_n$으로 $y = w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n$으로 표현**할 수 있으며, 
	가산성(Additreivityly)과 동차성(Homogeneity)을 만족해야 한다.

	- **가산성**: 임의의 수 $x, y$에 대해 $f(x+y) = f(x) + f(y)$가 성립
	- **동차성**: 임의의 수 $x, \alpha$에 대해 $f(\alpha x) = \alpha f(x)$가 성립

- **위의 조건을 만족하지 못하는 모델을 비선형 관계에 있는 모델**이라고 한다.
- 비선형 모델은 활성화 함수를 통해 표현할 수 있고 이러한 비선형 관계를 통해 복잡한 표현이 가능해져 복잡한 문제를 해결할 수 있게된다.

---
## ReLU 문제점

![Pasted image 20250304150548.png](/img/user/images/Pasted%20image%2020250304150548.png)
- Dead ReLU: ReLU는 결과값이 음수인 경우 모두 0으로 취급하는데, back propagation시 기울기에 0이 곱해져 해당 부분의 뉴런은 죽고 그 이후의 뉴런 모두 죽게 된다. 
	&rarr; Leaky ReLU는 값이 음수일 때 조금의 음의 기울기를 갖도록 하여 뉴런이 조금이라도 기울기를 갖도록 한다. 또 다른 방법으로는 입력값에 아주 조금의 편향(bias)를 주어 ReLU를 왼쪽으로 조금 이동시키는 방법이 있다.

- Bias Shift(편향 이동): ReLU는 항상 0이상의 값을 출력하기 때문에 활성화값의 평균이 0보다 커 zero-centered하지 않다. 활성화값이 zero-centered되지 않으면 가중치 업데이트가 동일한 방향으로만 업데이트가 돼서 학습 속도가 느려질 수가 있다.

- 이러한 문제를 해결하기 위해 Batch Nomalization을 사용하거나 zero-centered된 ELU, SeLU와 같은 활성화 함수를 사용한다.
> [!용어]
> - Zero-Centered: 평균(또는 기대값)이 0에 가깝도록 전처리하거나 변환한 상태를 말합니다.

--- 
## 편향은 왜 존재하는가

![Pasted image 20250304150832.png](/img/user/images/Pasted%20image%2020250304150832.png)
- 편향(bias): 가중치의 선형 결합에 추가로 더해지는 상수 항을 말합니다.
	$y = W \cdot x + b$
	$x$: 입력 벡터
	$W$: 가중치(Weight)
	$b$: 편향(Bias)
	$y$: 뉴런의 출력
	
	활성화 함수가 왼쪽 혹은 오른쪽으로 이동한다. 가중치(weight)는 활성화 함수의 가파른 정도 즉, 기울기를 조절하는 반면, 편향(bias)는 **활성화 함수를 움직임으로써 데이터에 더 잘 맞도록 한다.**

## Gradient Descent

- Gradient Descent: 어떤 함수의 극소점을 찾기 위해 gradient 반대 방향으로 이동해 가는 방법이다.
	![Pasted image 20250304151308.png](/img/user/images/Pasted%20image%2020250304151308.png)
	Loss function을 최소화시키기 위해 파라미터에 대해 Loss function을 미분하여 그 기울기값(gradient)을 구하고, 경사가 하강하는 방향으로 파라미터 값을 점진적으로 찾기위해 사용된다.
	Gradient Descent를 수식으로 표현하면 아래와 같다.
	$W_{t+1}←W_t−ηg_t$
	- $W_t$ : 현재 시점 t의 가중치
	- $g_t$ : 현재 가중치 $W_t$에서의 비용함수 기울기
	- $η$ : 학습률(lr)
	
	- 문제점
		1. 적절한 Step size(lr)이 필요함 &rarr; 너무 크면 빠르게 수렴하지만 최소값에 수렴이 안되고 발산할 수 있다. 너무 작으면 시간이 너무 오래 걸린다.
			![Pasted image 20250304151630.png](/img/user/images/Pasted%20image%2020250304151630.png)
		2. Local Minimum에 빠질 수 있다. &rarr; local minimum이 global minimum이라고 착각하여 빠져나오지 못할 수 있다.
			![Pasted image 20250304151644.png](/img/user/images/Pasted%20image%2020250304151644.png)

---
## 꼭 Gradient를 써야 할까? 그 그래프에서 가로축과 세로축 각각은 무엇인가? 실제 상황에서는 그 그래프가 어떻게 그려질까?
![Pasted image 20250304151749.png](/img/user/images/Pasted%20image%2020250304151749.png)
- Gradient가 양수이면 올라가는 방향이며 음수이면 내려가는 방향이다. 실제 상황에서는 Gradient 그래프가 0을 중심으로 진동하는 모양이 될 것이다.

---
## GD 중에 때때로 Loss가 증가하는 이유는?

![Pasted image 20250304151914.png](/img/user/images/Pasted%20image%2020250304151914.png)
- minima에 들어갔다가 나오는 경우일 것이다. 실제로 사용되는 GD에서는 local minima 문제를 피하기 위해 Momentum 등의 개념을 도입한 RMSprop, Adam 등의 optimization 전략을 사용한다.
	
	각 optimization 전략에 따라 gradient가 양수인 방향으로도 parameter update step을 가져가는 경우가 생길 수 있으며, 이 경우에는 Loss가 일시적으로 증가할 수 있다.

---
## Back Propagation

![Pasted image 20250304152140.png](/img/user/images/Pasted%20image%2020250304152140.png)
- **역전파 알고리즘**: Loss에 대한 입력값의 기울기(미분값)를 출력층 layer에서부터 계산하여 거꾸로 전파시키는 것이다.
	최종적으로 출력층에서의 output값에 대한 입력층에서의 input data의 기울기 값을 구할 수 있다.
	
	이 과정에서 chain rule이 사용된다
		출력층 바로 전 layer에서부터 기울기(미분값)을 계산하고 이를 점점 거꾸로 전파시키면서 전 layer들에서의 기울기와 서로 곱하는 형식으로 나아가면 최종적으로 출력층의 output에 대한 입력층에서의 input의 기울기(미분값)을 구할 수가 있다.
- 과정
	- 순전파를 이용해 Loss 계산
	- **Chain Rule(연쇄 법칙)을 이용하여** 손실 함수의 각 파라미터에 대한 미분(gradient)을 계산합니다.
	- 출력층부터 시작해 입력층 방향으로, 각 계층의 활성화 함수 미분과 가중치에 대한 기울기를 순차적으로 구해 나갑니다.
	- 이를 통해 “오차가 각 파라미터에 어떻게 기여하는지”를 알 수 있습니다.
	- $W_{t+1}←W_t−ηg_t$ 를 통해 가중치 업데이트


---
## Local minima 문제에도 딥러닝이 잘 되는 이유

- Local minima 문제는 고차원의 공간에서는 발생하기 드문 문제이기 떄문이다. 
	실제 딥러닝 모델에서는 Weight가 수도 없이 많으며, 그 수많은 weight가 모두 local minima에 빠져야 문제가 발생하기에 발생하기 드물다.
	
	고차원의 공간에서는 모든 축의 공간이 오목한 형태일 확률도 매우 낮다. (0에 가깝다) 따라서 **대부분의 critical point는 Saddle point이다.** 
		![Pasted image 20250304152448.png](/img/user/images/Pasted%20image%2020250304152448.png)
		![Pasted image 20250304152615.png](/img/user/images/Pasted%20image%2020250304152615.png)
		
> [!용어]
    > - `critical point`: 일차 미분이 0인 지점이다. (local/global)minima, (local/global)maxima, saddle point를 가리킴
    > - `local minimum`: 모든 방향에서 극소값을 만족하는 
    > - `global minimum`: 모든 방향에서 극소값을 만족하는 점 중에 가장 값이 작은 점(정답)
    > - `saddle point`: 어느 방향에서 보면 극대값이지만 다른 방향에서 보면 극소값이 되는 점

---
## Gradient Descent가 Local Minima 문제를 피하는 방법

- **Momentum**: 관성을 의미하며 gradient의 방향성을 담고 있는 momentum인자를 통해 흐르던 방향을 어느 정도 유도시켜 local minima에 빠지지 않게 만든다.
	![Pasted image 20250304152810.png](/img/user/images/Pasted%20image%2020250304152810.png)

- **Nesterov Accelerated Gradient(NAG)**: **모멘텀과 비슷한 역할을 수행**하는 `Look-ahead gradient` 인자를 포함하여, a 라는 `accumulate gradient`가 gradient를 감소시키는 역할을 한다. **모멘텀과 다른 점은, 미리 한 스텝을 옮겨가본 후에 어느 방향으로 갈지 정한다는 것이다.**

- **Adagrad**:  뉴럴넷의 파라미터가 많이 바뀌었는지 적게 바뀌었는지 확인하고, **적게 변한건 더 크게 변하게 하고, 크게 변한건 더 작게 변화시키는 방법이다.**
	$G_t$가 계속 커지면 분모가 점점 무한대에 가까워지게 되어, $W$ 업데이트가 되지 않게 되어, **뒤로 갈수록 학습이 점점 안되는 문제점이 발생**
	![Pasted image 20250304152922.png](/img/user/images/Pasted%20image%2020250304152922.png)

- **Adadelta**: `Exponential Moving Average(EMA)`를 사용하여, **Adagrad의 $G_t$가 계속 커지는 현상을 막을 수 있다.**
	![Pasted image 20250304153036.png](/img/user/images/Pasted%20image%2020250304153036.png)

---
## 찾은 해가 Global Minimum인지 아닌지 알 수 있는 방법은?

- saddle point가 아닌 완전한 local minimum이 발생하는 경우는 희귀하다. 따라서 **모든 방향에서 아래로 볼록인 local minima를 발견한다면, 그 지점이 바로 global minima일 가능성이 높다.**

---
## Training set과 Test set을 나누는 이유

- 모델은 데이터에 대해 예측값을 만들고 정답과 비교하며 업데이트되면서 학습이 된다. 그런데 학습 데이터에 대해서는 좋은 성능을 낸다 하더라도 본 적 없는 데이터에 대해서는 잘 대응하지 못하는 **오버피팅** 문제가 생긴다면 좋은 모델이 아니다.

- 이를 막기 위해 학습된 모델이 처음 보는 데이터에도 강건하게 성능을 내는지 판단하기 위한 수단으로 test 세트를 따로 만든다.

---
## Validation set이 있는 이유

- 모델을 학습시키고 test 데이터를 통해 모델의 일반화 성능을 파악하고, 다시 모델에 새로운 시도를 하고 test 데이터를 통해 모델의 성능을 파악한다고 생각해보자.

- 이 경우, **모델은 결국 test 데이터에도 오버피팅이 되어 다시 처음 보는 데이터를 주면 좋은 성능을 보장할 수 없게 된다.**

- 이 문제를 막기 위해 validation 세트를 사용한다. **validation 세트를 통해 모델의 성능을 평가하고 하이퍼파라미터 등을 수정하는 것이다.**

- 즉, train 데이터로 모델을 학습시키고 valid 데이터로 학습된 모델의 성능 평가를 하고 더 좋은 방향으로 모델을 수정한다. 그리고 최종적으로 만들어진 모델로 **test 데이터를 통해 최종 성능을 평가한다.**

---
## Test set이 오염되었다는 의미

- Test 데이터는 한 번도 학습에서 본 적 없는 데이터여야 한다. 그런데 train 데이터가 test 데이터와 흡사하거나 포함되기까지 한다면 test 데이터는 더이상 학습된 모델의 성능 평가를 객관적으로 하지 못한다.

- 이렇듯 **test 데이터가 train 데이터와 유사하거나 포함된 경우에 test 세트가 오염**되었다고 말한다.

---
## Batch Normalization의 효과
- 배치 정규화: 학습 시 **미니배치 단위로 입력의 분포가 평균이 0, 분산이 1이 되도록 정규화**한다. 더불어 $γ$로 스케일과 $β$로 이동 변환을 수행한다.
	- 장점1: **기울기 소실/폭발 문제가 해결**되어 큰 학습률을 설정할 수 있어 **학습속도가 빨라진다.**
	- 장점2: 항상 입력을 정규화시키기 때문에 **가중치 초깃값에 크게 의존하지 않아도 된다.**
	- 장점3: 자체적인 규제(Regularization) 효과가 있어 **Dropout이나 Weight Decay와 같은 규제 방법을 사용하지 않아도 된다.**

- 주의사항
	학습 과정에서는 미니 배치의 평균과 분산을 계산하여 배치 정규화를 적용하지만, **추론 시에는 학습 데이터 전체에 대한 평균과 분산을 계산하여 적용을 해야 한다.** 왜냐하면 사용자가 설정한 배치의 크기에 따라 추론 결과가 변할 수도 있기 때문이다.
	
---
## GAN에서 Generator 쪽에도 BN을 적용 가능?
- 일반적으로 GAN에서는 생성기(Generator)의 출력층(Output Layer)에만 BN(Batch Normalization)을 적용하지 않는다. **왜냐하면 생성기가 만든 이미지가 BN을 지나면 실제 이미지와는 값의 범위가 달라지기 때문이다.**

---
## SGD, RMSprop, Adam

![Pasted image 20250304154129.png](/img/user/images/Pasted%20image%2020250304154129.png)

- **GD**: Loss Function을 계산할 때 전체 train set을 사용하는 것을 Batch Gradient Descent 라고 한다.

- **SGD**: loss function을 계산할 때 전체 데이터(batch) 대신 데이터 한 개 또는 일부 조그마한 데이터의 모음(mini-batch)에 대해서만 loss function을 계산한다.
	
	이 방법은 batch gradient descent 보다 다소 부정확할 수는 있지만, 훨씬 계산 속도가 빠르기 때문에 같은 시간에 더 많은 step을 갈 수 있으며 여러 번 반복할 경우 보통 batch의 결과와 유사한 결과로 수렴한다.

- **RMSprop**: Adagrad의 단점을 해결하기 위한 방법이다.
	Adagrad의 식에서 gradient의 제곱값을 더해나가면서 구한 Gt부분을 합이 아니라 지수평균으로 바꾸어서 대체한 방법이다.
	
	이렇게 대체를 할 경우 Adagrad처럼 Gt가 무한정 커지지는 않으면서 최근 변화량의 변수간 상대적인 크기 차이는 유지할 수 있다.
	![Pasted image 20250304154032.png](/img/user/images/Pasted%20image%2020250304154032.png)

- **Adam**: RMSProp과 Momentum 방식을 합친 것 같은 알고리즘이다.
	이 방식에서는 Momentum 방식과 유사하게 지금까지 계산해온 기울기의 지수평균을 저장하며, RMSProp과 유사하게 기울기의 제곱값의 지수평균을 저장한다.

---
## 미니 배치 크기

- 미니 배치가 작을 때의 장점
	1. 한 iteration의 계산량이 적어지기 때문에 step 당 속도가 빨라진다.
	2. 적은 Vram으로 학습이 가능하다.
- 단점
	1. 데이터 전체의 경향을 반영하기 힘들다. 업데이트를 항상 좋은 방향으로 하지만은 않는다.
