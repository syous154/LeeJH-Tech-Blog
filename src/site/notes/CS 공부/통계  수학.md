---
{"dg-publish":true,"permalink":"/cs//","created":"2025-02-27T13:26:33.196+09:00","updated":"2025-02-27T15:20:27.559+09:00"}
---

## 고유값과 고유벡터란?

- 선형대수학에서 주어진 정방행렬(row, col의 수가 같은) $A$가 있을 때, 어떤 0이 아닌 벡터 $v$에 대해
	$A\mathbf{v} = \lambda \mathbf{v}$
	를 **만족하는 스칼라 $\lambda$와 벡터 $v$를 각각 고유값, 고유벡터라고 한다**
	
	따라서 $A$가 선형변환을 나타낸다고 할 수 있고 이때 고유벡터는 선형변환 $A$에 의해 **'방향은 그대로 유지하면서'** 길이만 변하는 벡터이다
	
	어떤 벡터 $v$가 고유벡터라는 것은 $v$는 $A$에 의해 변환되더라도 고유한 방향을 잃지 않는 다는 것을 의미한다.
	
	**고유값**과 **고유벡터**는 선형변환(또는 행렬)의 가장 중요한 특징 중 하나로, 변환이 벡터에 미치는 영향을 ‘축 방향(고유벡터)’과 그 ‘크기 변화 비율(고유값)’로 파악할 수 있게 해 줍니다.
	- 고유값 $\lambda$는 $\det(A - \lambda I) = 0$이라는 특성방정식을 통해 구합니다.
	- 특정 $\lambda$에 대한 고유벡터는 $(A - \lambda I)\mathbf{v} = \mathbf{0}$를 풀어서 구합니다.
	
	이러한 고유값과 고유벡터는 PCA와 같은 기술에서 활용됩니다.

##  샘플링(Sampling)과 리샘플링(Resampling)이란?

- 샘플링: **표본추출**을 한다는 의미, 모집단 전체에 대한 추정치를 얻기 위해 임의의 sample을 선택
	모집단을 전부 조사할 수 없을 때 사용하며 모집단 전체와 비슷하지만 완전히 동일하다고는 볼 수 없다. = **noise가 존재할 수 밖에 없다.**

- 리샘플링: 모집단의 분포형태를 알 수 없을 때 주로 사용하는 방법, 
	**현재 가지고 있는 데이터를 통해 모집단의 분포와 가장 비슷한 분포를 만들자!** 라는 개념
	가지고 있는 샘플에서 다시 샘플을 추출 하여 통계량의 변동성을 확인, **즉 샘플링을 여러번 반복하는 방법**
	**K-Fold 교차 검증이 대표적인 예시**
	
	표본을 추출하면서 원래 데이터 셋을 복원하기 떄문에 이를 통해서 모집단의 분포에 어떤 가정도 필요없이 **표본만으로 추론이 가능하다는 장점이 있다.**

## 확률 모형과 확률 변수란?

- 확률변수: 표본 공간의 각 단위 사건에 실수 값을 부여하는 변수, 특정 확률로 발생하는 각각의 결과를 수치적 값으로 표현하는 변수라고 할 수 있다
	이산 확률 변수, 연속 확률 변수 두가지의 경우로 나눌 수 있다
	- 이산 확률 변수: 확률 변수 $X$가 취할 수 있는 값이 유한하기 때문에 셀 수 있는 확률 변수
	- 연속 확률 변수: 어떤 두 수 사이에 반드시 다른 수가 존재하는, 셀 수 없는 범위의 확률변수를 가지는 경우
	```
	일단 주사위를 굴리는 상황은 어떤 수가 나올지 모르므로, 확률상황이다.
	"주사위를 굴렸을 때 나오는 값"을 확률변수 X라고 할 수 있다.1~6이 표본공간이 되고, 
	셀 수 있으므로 이산확률변수가 된다.P(X=1)와 같은 식으로 표현하고, 
	이는 "주사위를 굴렸을 때, 1이라는 값이 나올 확률"로 해석할 수 있다.
	```

- 확률 모형: 확률 변수를 이용하여 데이터의 분포를 수학적으로 정의한 모형,
	데이터의 분포를 묘사하기 위해 사용, **보통 확률 분포 함수 or 확률 밀도 함수를 주로 사용**한다.
	이때 함수의 계수를 분포의 모수(Parameter)라고 부른다.
	확률 분포는 표본공간에서 정의된 확률을 이용하여 확률을 표현한 것, 대표적인 예시가 가우시안 분포

## 누적 분포 함수와 확률 밀도 함수의 정의와 수식
- 확률 변수 X가 임의의 실수 집합 B에 포함되는 사건의 확률이 다음과 같이 어떤 음이 아닌 함수 f의 적분으로 주어진다고 하자.
	$P(X∈B)=∫Bf(x)dx$

	이 때의 X를 연속확률변수라고 하며, 함수 f(x)를 **확률 밀도 함수(Probability Density Function, PDF)**라고 한다. 단, 실수 집합 B가 실수 전체일 경우 실수 전체에 대한 확률밀도함수의 적분은 1을 만족해야 한다.
	
	$P(X∈R)=∫Rf(x)dx=1$

	**누적 분포 함수(Cumulative Distribution Function, CDF)**는 확률변수가 특정 값보다 작거나 같을 확률을 나타내는 함수이다. 특정 값을 a라고 할 때, 누적 분포 함수는 다음과 같이 나타낼 수 있다.
	
	$F(a)=P(X≤a)=∫−∞af(x)dx$

	확률 밀도 함수와 누적 분포 함수는 **미분과 적분의 관계**를 갖는다. 확률 밀도 함수를 음의 무한대에서 특정값 a까지 적분을 하면, a에 대한 누적 분포 함수를 얻을 수 있다. 반대로 누적 분포 함수를 미분하면 확률 밀도 함수를 얻을 수 있다.

## 조건부 확률

- 정의: 사건 $A$가 일어났다는 전제 하에 사건 $B$가 일어날 확률, $P(B|A)=P(B∩A)/P(A)$로 표현 가능
	이는 베이즈 정리와도 이어진다.

- 베이즈 정리
	![Pasted image 20250227143646.png](/img/user/Pasted%20image%2020250227143646.png)
	- 변수 설명
		D: 새로 관찰되는 데이터
		θ: 모델에서 계산하고 싶어하는 모수 (가설)
		사후확률(Posterior): 데이터를 관찰했을 때, 이 가설이 성립할 확률 (데이터 관찰 이후 측정하기 때문에 사후확률)
		사전확률(Prior): 가설에 대해 사전에 세운 확률 (데이터 관측 이후 사후확률이 사전확률이 된다.)
		가능도(Likelihood): 현재 주어진 모수 (가정) 에서 이 데이터가 관찰될 가능성
		증거(Evidence): 데이터 전체의 분포 

## 공분산과 상관계수

- 공분산: 확률변수 $X$의 편차와 확률변수 $Y$의 편차를 곱한 것의 평균값
	
	$Cov(X,Y)=E((X−μX)(Y−μY))$
	
	두 변수 간에 양의 상관관계가 있는지, 음의 상관관계가 있는지 정도를 알 수 있다. 하지만 그 상관관계가 얼마나 큰지는 제대로 반영하지 못한다.
	
	문제점: 확률변수의 단위 크기에 영향을 많이 받는다. 
	→ 상관계수를 사용

- 상관 계수: 확률변수의 절대적 크기에 영향을 받지 않도록 공분산을 단위화, 즉 공분산에 각 확률변수의 분산을 나눈다
	$$
	\rho = \frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)\,\mathrm{Var}(Y)}} \quad,\quad -1 \le \rho \le 1
	$$
	
	상관계수는 양의 상관관계가 있는지 음의 상관관계가 있는지 알려줄 뿐만 아니라, 그 상관성이 얼마나 큰지도 알려준다.
	
	1에 가까울 수록 크고 0에 가까울 수로 작다.

## 신뢰 구간
![Pasted image 20250227145228.png](/img/user/Pasted%20image%2020250227145228.png)
- 정의: 모집단의 모수가 위치해 있을 것으로 신뢰할 수 있는 구간
	신뢰구간을 구하는 이유는 모수의 신뢰성을 가늠하기 위해서이다.
	95% 신뢰구간이 $[a, b]$로 주어졌다고 했을 때, 이는 “많은 표본을 반복 추출하여 동일한 방식으로 95% 신뢰구간을 구하면, 그 중 95%가 실제 모집단의 모수를 포함하게 된다” 라는 의미이다.

## P-value

- p-value를 알기 위해서는 먼저 **1종 오류**를 알아야 한다. 여기서 1종 오류란 **귀무가설이 참인데 기각한 경우**을 말한다. **귀무가설이란 기존의 주장**을 말하며, 이와 **반대로 새로운 주장을 대립가설**이라고 한다.
	
	예를 들어, 어느 제약회사에서 치료약 A를 개발했다. 기존에는 치료약 A가 없었으므로 귀무가설은 "치료약 A가 효과가 없다"라고 설정한다. 반대로 대립가설은 "치료약 A는 효과가 있다"로 설정한다. 회사에서는 검정을 한 결과, 귀무가설을 기각하고 대립가설을 채택했다. 치료약 A는 판매되었고 높은 매출을 기록했다. 그런데 알고보니 치료약 A가 효과가 없다는 것이 밝혀졌다. 참인 귀무가설을 기각했기에 이는 1종 오류가 일어났다고 볼 수 있다.
	
	다시 돌아와서 p-value는 **1종 오류를 범할 확률**을 말한다. 예를 들어, p-value가 5%라면, 100번 중 5번 1종 오류가 발생한다는 말이다. 검정을 할 때는 유의 수준 α를 정하는데, 이것이 1종 오류의 상한선이 된다. 그래서 유의 수준보다 p-value가 작다면 실험의 오류가 상한선보다 작으므로 귀무가설을 기각하고 대립가설을 채택한다. 만약 크다면 상한선을 넘었으므로 귀무가설을 채택한다.

## R square의 의미

- 결정 계수(R square)는 선형 회귀 모델에서 데이터에 대해 회귀선이 얼마나 잘 설명하는지에 대한 설명력을 의미
	결정계수는 0~1의 값을 가질 수 있고, 만약 값이 1이라면 회귀선으로 모든 데이터를 다 설명할 수 있다고 이해할 수 있다. 반대로 0에 가까울수록 설명력이 거의 없음을 의미한다.
	
	결정계수는 다음의 식으로 구할 수 있다.
	$$
	R2=SSE/SST=1−SSR/SST
	$$
	- $SSE=∑(추정값 - 실제값 평균)^2$
	- $SST=∑(관측값 - 실제값 평균)^2$
	- $SSR=∑(실제값 - 추정값)^2$
	이외에도 MAE, MSE, RMSE등이 있다.
	
	- 주의사항
		- (독립)변수 수가 늘어나게 되면 $R^2$는 보통 증가하게 된다.
		- 변수가 무작정 많아져 $R^2$를 높일 수 있어 과적합 가능성이 존재한다.
		- $R^2$이 높다고 해서 인과관계가 성립한다고는 할 수 없다.
		- 단순 선형 회귀에서만 사용가능하다.

## 평균(mean)과 중앙값(median)의 사용기준
- `평균(mean)`: 모든 관측값의 합을 자료의 개수로 나눈 것
	전체 관측값(실제값)이 **고루 분포되어 있고, 평균 근처에 표본이 몰려 있는 상황**에서 대표값으로 유용
	이상치와 같은 극단적인 값에 영향을 크게 받는다.
	
- `중앙값(median)`: 전체 관측값을 크기 순서로 배열했을 때 가운데 위치하는 값
	평균과 달리 관측값들의 변화에 민감하지 않고, 이상치와 같은 극단적인 값에 영향을 거의 받지 않는다.
	표본의 편차, 왜곡이 심하게 나타나는 경우에 유용하다.

## 중심극한정리가 유용한 이유
- 
